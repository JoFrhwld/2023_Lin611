{
  "hash": "214421d5cd132395f9104d2bac139a92",
  "result": {
    "markdown": "---\ntitle: \"Downloading OSF Data\"\nauthor: \"Josef Fruehwald\"\ndate: 2023-01-17\ncategories:\n  - osf\n  - data download\ncode-tools: true\norder: 04\n---\n\n\nThe data for winter's Statistics for Linguistics textbook is all available on the Open Science Framework at <https://osf.io/34mq9/> You can download the files as you need them and upload them into your blog files, or you can download the whole thing at once with this quarto notebook and the [`osfr`](https://docs.ropensci.org/osfr/) package.\n\nI'm effectively just running through their sample documentation from the about page.\n\n## Step 1 - Install `osfr` and load it\n\nThis will check to see of `osfr` is installed. If it is, it will load it. If not, it will install it, then load it. This may start printing out scary looking things like `g++ -std=gnu++14 -I\"/usr/share/R/include\"` and so forth. That is ok.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nosfr_exists <- require(\"osfr\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: osfr\n```\n:::\n\n```{.r .cell-code}\nif(!osfr_exists){\n  install.packages(\"osfr\")\n  library(osfr)\n}\n```\n:::\n\n\n## Step 2 - Download the data\n\nThe little string of letters and numbers comes from the osf link. I've included some `if()`s in there to be defensive, just in case you re-run the code so you won't accidentally delete or overwrite anything.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# I'm just being defensive here,\n# in case you've run the script before.\ndata_exists <- dir.exists(\"data\")\nif(!data_exists){\n  dir.create(path = \"data\")\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_files <- list.files(\"data\")\nif(length(data_files) != 17){\n  osf_retrieve_node('34mq9') |> \n    osf_ls_files(\n      \"materials/data\", \n      n_max = Inf\n    ) |> \n    osf_download(\n      path = \"data\",\n      conflicts = \"skip\"\n    )\n}\n```\n:::\n\n\n## Step 3 - Load the data into your blog post.\n\nThere are two ways to go about loading the data into a quarto notebook for your work-through blog post.\n\n### Way 1\n\nI've assumed you've run the `download_data.qmd` code from the main workthrough blog directory. So, from any given blog post in `posts/XX_chapter/index.qmd` file, you'd need to type\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnettle_df <- read.csv(\"../../data/nettle_1999_climate.csv\")\n```\n:::\n\n\n### Way 2\n\nIn the file browser pane in RStudio, if you navigate to the `data` directory, click on the \"⚙️ More\" drop down menu. Then select *Copy Folder Path to Clipboard*. For me, this copies `~/work_through_blog/data` to the clipboard. You can then use this inside `read.csv()` like so:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnettle_df <- read.csv(\"~/work_through_blog/data/nettle_1999_climate.csv\")\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
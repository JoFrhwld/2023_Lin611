[
  {
    "objectID": "class_notes/2023-01-26_tidyverse2/index.html",
    "href": "class_notes/2023-01-26_tidyverse2/index.html",
    "title": "Continuing with the tidyverse",
    "section": "",
    "text": "library(tidyverse)\n\nA useful diagram for understanding joins https://r4ds.hadley.nz/joins.html#fig-join-left\n\n\n\n\n\n\nWork it out\n\n\n\n\num <- read_tsv(\"https://bit.ly/3JdeSbx\")\ndemo <- read_csv(\"https://bit.ly/3wOfcGx\")\n\nJoin these two datasets together (dplyr::left_join()) and find out\n\nWhich filled pause did people born before 1930 use the most?\nWhich filled pause did people born after 1980 use the most?\n\nThink of using functions like\n\ndplyr::filter()\ndplyr::count()\ndplyr::arrange()"
  },
  {
    "objectID": "class_notes/2023-01-26_tidyverse2/index.html#pivots",
    "href": "class_notes/2023-01-26_tidyverse2/index.html#pivots",
    "title": "Continuing with the tidyverse",
    "section": "Pivots",
    "text": "Pivots\n\ninstall.packages(\"nasapower\")\n\n\nlibrary(nasapower)\n\nGetting monthly temperature data\n\nlex_temp <- \n  get_power(\n    community = \"ag\",\n    temporal_api = \"monthly\",\n    pars = \"T2M\",\n    dates = c(\"1985-01-01\", \"2021-12-31\"),\n    lonlat = c(-84.501640,  38.047989)\n  )\n\nHere is monthly temperature data for Lexington according to NASA\n\nlex_temp\n\nNASA/POWER CERES/MERRA2 Native Resolution Monthly and Annual  \n Dates (month/day/year): 01/01/1985 through 12/31/2021  \n Location: Latitude  38.048   Longitude -84.5016  \n Elevation from MERRA-2: Average for 0.5 x 0.625 degree lat/lon region = 280.65 meters \n The value for missing source data that cannot be computed or is outside of the sources availability range: NA  \n Parameter(s):  \n \n Parameters: \n T2M     MERRA-2 Temperature at 2 Meters (C)  \n \n# A tibble: 37 √ó 17\n     LON   LAT PARAMETER  YEAR   JAN   FEB   MAR   APR   MAY   JUN   JUL   AUG\n   <dbl> <dbl> <chr>     <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1 -84.5  38.0 T2M        1985 -4.87 -3.06  7.64  13.5  17.4  21.0  23.8  23.1\n 2 -84.5  38.0 T2M        1986 -1.52  1.77  6.53  12.8  18.1  23.4  26.5  23.4\n 3 -84.5  38.0 T2M        1987 -0.99  1.08  6.54  10.8  19.7  22.8  25.4  25.7\n 4 -84.5  38.0 T2M        1988 -2.38 -0.56  5.58  11.0  17.2  23.6  26.4  26.2\n 5 -84.5  38.0 T2M        1989  2.42 -0.93  6.44  10.7  14.7  21.1  23.5  23.1\n 6 -84.5  38.0 T2M        1990  2.61  4.76  7.74  10.8  15.8  21.3  23.7  23.8\n 7 -84.5  38.0 T2M        1991 -0.54  2.13  7.15  13.5  20.4  22.3  24.3  24.3\n 8 -84.5  38.0 T2M        1992  0.09  3.51  6.23  11.7  15.9  19.8  23.6  20.9\n 9 -84.5  38.0 T2M        1993  1.78 -0.27  4.3   10.6  17.4  21.8  26.3  24.8\n10 -84.5  38.0 T2M        1994 -3.89  0.8   4.54  13.2  15.1  22.7  24.3  23.2\n# ‚Ä¶ with 27 more rows, and 5 more variables: SEP <dbl>, OCT <dbl>, NOV <dbl>,\n#   DEC <dbl>, ANN <dbl>\n\n\nPivoting long\n\nlex_long <- \n  lex_temp |> \n  pivot_longer(\n    cols = JAN:DEC,\n    names_to = \"month\",\n    values_to = \"temp\"\n  )\n\nlex_long\n\n# A tibble: 444 √ó 7\n     LON   LAT PARAMETER  YEAR   ANN month  temp\n   <dbl> <dbl> <chr>     <dbl> <dbl> <chr> <dbl>\n 1 -84.5  38.0 T2M        1985  12.0 JAN   -4.87\n 2 -84.5  38.0 T2M        1985  12.0 FEB   -3.06\n 3 -84.5  38.0 T2M        1985  12.0 MAR    7.64\n 4 -84.5  38.0 T2M        1985  12.0 APR   13.5 \n 5 -84.5  38.0 T2M        1985  12.0 MAY   17.4 \n 6 -84.5  38.0 T2M        1985  12.0 JUN   21.0 \n 7 -84.5  38.0 T2M        1985  12.0 JUL   23.8 \n 8 -84.5  38.0 T2M        1985  12.0 AUG   23.1 \n 9 -84.5  38.0 T2M        1985  12.0 SEP   19.8 \n10 -84.5  38.0 T2M        1985  12.0 OCT   15.5 \n# ‚Ä¶ with 434 more rows\n\n\nPivoting wide\nYou can do data operations, and then pivot the data back to wide.\n\nlex_long |> \n  # converting year to a decade value\n  mutate(decade = floor(YEAR / 10)) |> \n  # grouping by decade and month\n  group_by(decade, month) |> \n  # getting average temperature within groups\n  summarise(mean_temp = mean(temp)) |> \n  # pivoting wide\n  pivot_wider(\n    names_from = month,\n    values_from = mean_temp\n  )\n\n`summarise()` has grouped output by 'decade'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 5 √ó 13\n# Groups:   decade [5]\n  decade   APR   AUG    DEC   FEB    JAN   JUL   JUN   MAR   MAY   NOV   OCT\n   <dbl> <dbl> <dbl>  <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1    198  11.8  24.3 -0.564 -0.34 -1.47   25.1  22.4  6.55  17.4  7.50  12.4\n2    199  11.6  23.7  1.98   2.14  0.077  24.4  21.8  5.72  17.2  6.16  13.1\n3    200  12.7  24.5  1.08   1.23  0.158  24.1  22.3  6.86  17.7  7.34  13.6\n4    201  12.9  24.1  2.46   1.47 -0.838  24.7  22.7  6.26  18.6  6.08  14.0\n5    202  11.2  24.2  4.20   0.68  1.48   24.8  22.2  9.12  16.2  6.88  15.0\n# ‚Ä¶ with 1 more variable: SEP <dbl>\n\n\n\n\n\n\n\n\nWork it out\n\n\n\nWith the ‚ÄúUM‚Äù data\n\nCalculate the average duration of the vowel for each person for each word. Think of using functions like\n\ndplyr::mutate()\ndplyr::group_by()\ndplyr::summarise()\n\n\nFigure out how many times longer the vowel is in ‚ÄúUM‚Äù than for ‚ÄúUH‚Äù for each person. Think of using functions like\n\ntidyr::pivot_wider()\ndplyr::mutate()"
  },
  {
    "objectID": "class_notes/2023-01-26_tidyverse2/index.html#untidy-data-examples",
    "href": "class_notes/2023-01-26_tidyverse2/index.html#untidy-data-examples",
    "title": "Continuing with the tidyverse",
    "section": "Untidy data examples",
    "text": "Untidy data examples\nSource: untidydata by Joseph Casillas\n\ninstall.packages(\"devtools\")\ndevtools::install_github(\"jvcasillas/untidydata\")\n\n\nlibrary(untidydata)\n\nThis is just the nettle dataset all over again, but starts out ‚Äúlong‚Äù\n\nlanguage_diversity\n\n# A tibble: 444 √ó 4\n   Continent Country      Measurement Value\n   <chr>     <chr>        <chr>       <dbl>\n 1 Africa    Algeria      Langs          18\n 2 Africa    Angola       Langs          42\n 3 Oceania   Australia    Langs         234\n 4 Asia      Bangladesh   Langs          37\n 5 Africa    Benin        Langs          52\n 6 Americas  Bolivia      Langs          38\n 7 Africa    Botswana     Langs          27\n 8 Americas  Brazil       Langs         209\n 9 Africa    Burkina Faso Langs          75\n10 Africa    CAR          Langs          94\n# ‚Ä¶ with 434 more rows\n\n\n\n\n\n\n\n\nWork it out\n\n\n\nUsing a pivot _*() functions, convert the untidydata::language_diversity data to the format we‚Äôve seen the Nettle data in."
  },
  {
    "objectID": "class_notes/2023-01-26_tidyverse2/index.html#stretch-goals",
    "href": "class_notes/2023-01-26_tidyverse2/index.html#stretch-goals",
    "title": "Continuing with the tidyverse",
    "section": "Stretch goals",
    "text": "Stretch goals\nHere‚Äôs Spanish vowel data, also from untidydata.\n\nspanish_vowels\n\n# A tibble: 750 √ó 4\n   label        rep    f1    f2\n   <chr>      <int> <dbl> <dbl>\n 1 p01-male-a     1  615. 1231.\n 2 p01-male-a     2  645. 1282.\n 3 p01-male-a     3  608. 1248.\n 4 p01-male-e     1  477. 1612.\n 5 p01-male-e     2  457. 1839.\n 6 p01-male-e     3  445. 1849.\n 7 p01-male-i     1  309. 2153.\n 8 p01-male-i     2  259. 2176.\n 9 p01-male-i     3  337. 2015.\n10 p01-male-o     1  478.  865.\n# ‚Ä¶ with 740 more rows\n\n\nThe spanish_vowels$label column has three different variable smushed together: speaker id, speaker gender, vowel class. This is good file naming convention. Poor data column convention.\n\n\n\n\n\n\nWork it out\n\n\n\nLook over the docs for tidyr::separate() and try to get the speaker id, speaker gender, and vowel class separated out into their own columns."
  },
  {
    "objectID": "class_notes/2023-02-02_tidynorm/index.html",
    "href": "class_notes/2023-02-02_tidynorm/index.html",
    "title": "Tidy Vowel Normalization",
    "section": "",
    "text": "library(tidyverse)\nlibrary(khroma)\ntheme_set(theme_minimal())\n\n\nlibrary(untidydata)\n\n\ntidy_vowels <-\n  spanish_vowels |>\n  separate(\n    col = label,\n    sep = \"-\",\n    into = c(\"id\", \"gender\", \"vowel\")\n  ) |> \n  # Recoding gender labels\n  mutate(\n    gender = case_when(\n      gender == \"female\" ~ \"women\",\n      gender == \"male\" ~ \"men\"\n    )\n  )\n\n\ntidy_vowels |> \n  ggplot(aes(f2, f1, color = gender)) +\n    stat_density2d()+\n    scale_x_continuous(trans = \"reverse\")+\n    scale_y_continuous(trans = \"reverse\")+\n    scale_color_brewer(palette = \"Dark2\")"
  },
  {
    "objectID": "class_notes/2023-02-02_tidynorm/index.html#unnormalized-vowels",
    "href": "class_notes/2023-02-02_tidynorm/index.html#unnormalized-vowels",
    "title": "Tidy Vowel Normalization",
    "section": "Unnormalized vowels",
    "text": "Unnormalized vowels\n\ntidy_vowels |> \n  ggplot(aes(x = gender))+\n    geom_violin(aes(y = f1, fill = \"f1\"))+\n    geom_violin(aes(y = f2, fill = \"f2\")) +\n    scale_y_continuous(trans = \"log10\")+\n    scale_fill_bright()+\n    labs(y = \"frequency (hz)\")"
  },
  {
    "objectID": "class_notes/2023-02-02_tidynorm/index.html#normalizing",
    "href": "class_notes/2023-02-02_tidynorm/index.html#normalizing",
    "title": "Tidy Vowel Normalization",
    "section": "Normalizing",
    "text": "Normalizing\nz-scoring a.k.a. ‚ÄúLobanov‚Äù\nLog-mean\nLog-mean normalization, following Barreda (2021)."
  },
  {
    "objectID": "class_notes/2023-01-10/index.html",
    "href": "class_notes/2023-01-10/index.html",
    "title": "Welcome Day",
    "section": "",
    "text": "An illustration of R vs RStudio vs Quarto\n\n\nR (on the left) is a programming language, which looks at (üëÄ) R scipt files (the box with .r) and interprets them. RStudio is an IDE (Integrated Development Environment) that provides a more pleasant interface to working with R.\nQuarto (not pictured) is a program that interprets Quarto documents (the box with .qmd) and renders them as html files. We'll be doing this all inside of RStudio."
  },
  {
    "objectID": "class_notes/2023-01-10/index.html#examples-from-inside-class",
    "href": "class_notes/2023-01-10/index.html#examples-from-inside-class",
    "title": "Welcome Day",
    "section": "Examples from inside class",
    "text": "Examples from inside class\nThis was an example of inserting an R code chunk into a quarto notebook\n\n```{r}\n1+1\n```\n\n[1] 2\n\n\nThis was an example of making a plot in quarto\n\n```{r}\nplot(cars)\n```\n\n\n\n\nThis was an example of running R code from Winters (2019). This particular code prints out all of the named colors in R.\n\n```{r}\ncolors()\n```\n\n  [1] \"white\"                \"aliceblue\"            \"antiquewhite\"        \n  [4] \"antiquewhite1\"        \"antiquewhite2\"        \"antiquewhite3\"       \n  [7] \"antiquewhite4\"        \"aquamarine\"           \"aquamarine1\"         \n [10] \"aquamarine2\"          \"aquamarine3\"          \"aquamarine4\"         \n [13] \"azure\"                \"azure1\"               \"azure2\"              \n [16] \"azure3\"               \"azure4\"               \"beige\"               \n [19] \"bisque\"               \"bisque1\"              \"bisque2\"             \n [22] \"bisque3\"              \"bisque4\"              \"black\"               \n [25] \"blanchedalmond\"       \"blue\"                 \"blue1\"               \n [28] \"blue2\"                \"blue3\"                \"blue4\"               \n [31] \"blueviolet\"           \"brown\"                \"brown1\"              \n [34] \"brown2\"               \"brown3\"               \"brown4\"              \n [37] \"burlywood\"            \"burlywood1\"           \"burlywood2\"          \n [40] \"burlywood3\"           \"burlywood4\"           \"cadetblue\"           \n [43] \"cadetblue1\"           \"cadetblue2\"           \"cadetblue3\"          \n [46] \"cadetblue4\"           \"chartreuse\"           \"chartreuse1\"         \n [49] \"chartreuse2\"          \"chartreuse3\"          \"chartreuse4\"         \n [52] \"chocolate\"            \"chocolate1\"           \"chocolate2\"          \n [55] \"chocolate3\"           \"chocolate4\"           \"coral\"               \n [58] \"coral1\"               \"coral2\"               \"coral3\"              \n [61] \"coral4\"               \"cornflowerblue\"       \"cornsilk\"            \n [64] \"cornsilk1\"            \"cornsilk2\"            \"cornsilk3\"           \n [67] \"cornsilk4\"            \"cyan\"                 \"cyan1\"               \n [70] \"cyan2\"                \"cyan3\"                \"cyan4\"               \n [73] \"darkblue\"             \"darkcyan\"             \"darkgoldenrod\"       \n [76] \"darkgoldenrod1\"       \"darkgoldenrod2\"       \"darkgoldenrod3\"      \n [79] \"darkgoldenrod4\"       \"darkgray\"             \"darkgreen\"           \n [82] \"darkgrey\"             \"darkkhaki\"            \"darkmagenta\"         \n [85] \"darkolivegreen\"       \"darkolivegreen1\"      \"darkolivegreen2\"     \n [88] \"darkolivegreen3\"      \"darkolivegreen4\"      \"darkorange\"          \n [91] \"darkorange1\"          \"darkorange2\"          \"darkorange3\"         \n [94] \"darkorange4\"          \"darkorchid\"           \"darkorchid1\"         \n [97] \"darkorchid2\"          \"darkorchid3\"          \"darkorchid4\"         \n[100] \"darkred\"              \"darksalmon\"           \"darkseagreen\"        \n[103] \"darkseagreen1\"        \"darkseagreen2\"        \"darkseagreen3\"       \n[106] \"darkseagreen4\"        \"darkslateblue\"        \"darkslategray\"       \n[109] \"darkslategray1\"       \"darkslategray2\"       \"darkslategray3\"      \n[112] \"darkslategray4\"       \"darkslategrey\"        \"darkturquoise\"       \n[115] \"darkviolet\"           \"deeppink\"             \"deeppink1\"           \n[118] \"deeppink2\"            \"deeppink3\"            \"deeppink4\"           \n[121] \"deepskyblue\"          \"deepskyblue1\"         \"deepskyblue2\"        \n[124] \"deepskyblue3\"         \"deepskyblue4\"         \"dimgray\"             \n[127] \"dimgrey\"              \"dodgerblue\"           \"dodgerblue1\"         \n[130] \"dodgerblue2\"          \"dodgerblue3\"          \"dodgerblue4\"         \n[133] \"firebrick\"            \"firebrick1\"           \"firebrick2\"          \n[136] \"firebrick3\"           \"firebrick4\"           \"floralwhite\"         \n[139] \"forestgreen\"          \"gainsboro\"            \"ghostwhite\"          \n[142] \"gold\"                 \"gold1\"                \"gold2\"               \n[145] \"gold3\"                \"gold4\"                \"goldenrod\"           \n[148] \"goldenrod1\"           \"goldenrod2\"           \"goldenrod3\"          \n[151] \"goldenrod4\"           \"gray\"                 \"gray0\"               \n[154] \"gray1\"                \"gray2\"                \"gray3\"               \n[157] \"gray4\"                \"gray5\"                \"gray6\"               \n[160] \"gray7\"                \"gray8\"                \"gray9\"               \n[163] \"gray10\"               \"gray11\"               \"gray12\"              \n[166] \"gray13\"               \"gray14\"               \"gray15\"              \n[169] \"gray16\"               \"gray17\"               \"gray18\"              \n[172] \"gray19\"               \"gray20\"               \"gray21\"              \n[175] \"gray22\"               \"gray23\"               \"gray24\"              \n[178] \"gray25\"               \"gray26\"               \"gray27\"              \n[181] \"gray28\"               \"gray29\"               \"gray30\"              \n[184] \"gray31\"               \"gray32\"               \"gray33\"              \n[187] \"gray34\"               \"gray35\"               \"gray36\"              \n[190] \"gray37\"               \"gray38\"               \"gray39\"              \n[193] \"gray40\"               \"gray41\"               \"gray42\"              \n[196] \"gray43\"               \"gray44\"               \"gray45\"              \n[199] \"gray46\"               \"gray47\"               \"gray48\"              \n[202] \"gray49\"               \"gray50\"               \"gray51\"              \n[205] \"gray52\"               \"gray53\"               \"gray54\"              \n[208] \"gray55\"               \"gray56\"               \"gray57\"              \n[211] \"gray58\"               \"gray59\"               \"gray60\"              \n[214] \"gray61\"               \"gray62\"               \"gray63\"              \n[217] \"gray64\"               \"gray65\"               \"gray66\"              \n[220] \"gray67\"               \"gray68\"               \"gray69\"              \n[223] \"gray70\"               \"gray71\"               \"gray72\"              \n[226] \"gray73\"               \"gray74\"               \"gray75\"              \n[229] \"gray76\"               \"gray77\"               \"gray78\"              \n[232] \"gray79\"               \"gray80\"               \"gray81\"              \n[235] \"gray82\"               \"gray83\"               \"gray84\"              \n[238] \"gray85\"               \"gray86\"               \"gray87\"              \n[241] \"gray88\"               \"gray89\"               \"gray90\"              \n[244] \"gray91\"               \"gray92\"               \"gray93\"              \n[247] \"gray94\"               \"gray95\"               \"gray96\"              \n[250] \"gray97\"               \"gray98\"               \"gray99\"              \n[253] \"gray100\"              \"green\"                \"green1\"              \n[256] \"green2\"               \"green3\"               \"green4\"              \n[259] \"greenyellow\"          \"grey\"                 \"grey0\"               \n[262] \"grey1\"                \"grey2\"                \"grey3\"               \n[265] \"grey4\"                \"grey5\"                \"grey6\"               \n[268] \"grey7\"                \"grey8\"                \"grey9\"               \n[271] \"grey10\"               \"grey11\"               \"grey12\"              \n[274] \"grey13\"               \"grey14\"               \"grey15\"              \n[277] \"grey16\"               \"grey17\"               \"grey18\"              \n[280] \"grey19\"               \"grey20\"               \"grey21\"              \n[283] \"grey22\"               \"grey23\"               \"grey24\"              \n[286] \"grey25\"               \"grey26\"               \"grey27\"              \n[289] \"grey28\"               \"grey29\"               \"grey30\"              \n[292] \"grey31\"               \"grey32\"               \"grey33\"              \n[295] \"grey34\"               \"grey35\"               \"grey36\"              \n[298] \"grey37\"               \"grey38\"               \"grey39\"              \n[301] \"grey40\"               \"grey41\"               \"grey42\"              \n[304] \"grey43\"               \"grey44\"               \"grey45\"              \n[307] \"grey46\"               \"grey47\"               \"grey48\"              \n[310] \"grey49\"               \"grey50\"               \"grey51\"              \n[313] \"grey52\"               \"grey53\"               \"grey54\"              \n[316] \"grey55\"               \"grey56\"               \"grey57\"              \n[319] \"grey58\"               \"grey59\"               \"grey60\"              \n[322] \"grey61\"               \"grey62\"               \"grey63\"              \n[325] \"grey64\"               \"grey65\"               \"grey66\"              \n[328] \"grey67\"               \"grey68\"               \"grey69\"              \n[331] \"grey70\"               \"grey71\"               \"grey72\"              \n[334] \"grey73\"               \"grey74\"               \"grey75\"              \n[337] \"grey76\"               \"grey77\"               \"grey78\"              \n[340] \"grey79\"               \"grey80\"               \"grey81\"              \n[343] \"grey82\"               \"grey83\"               \"grey84\"              \n[346] \"grey85\"               \"grey86\"               \"grey87\"              \n[349] \"grey88\"               \"grey89\"               \"grey90\"              \n[352] \"grey91\"               \"grey92\"               \"grey93\"              \n[355] \"grey94\"               \"grey95\"               \"grey96\"              \n[358] \"grey97\"               \"grey98\"               \"grey99\"              \n[361] \"grey100\"              \"honeydew\"             \"honeydew1\"           \n[364] \"honeydew2\"            \"honeydew3\"            \"honeydew4\"           \n[367] \"hotpink\"              \"hotpink1\"             \"hotpink2\"            \n[370] \"hotpink3\"             \"hotpink4\"             \"indianred\"           \n[373] \"indianred1\"           \"indianred2\"           \"indianred3\"          \n[376] \"indianred4\"           \"ivory\"                \"ivory1\"              \n[379] \"ivory2\"               \"ivory3\"               \"ivory4\"              \n[382] \"khaki\"                \"khaki1\"               \"khaki2\"              \n[385] \"khaki3\"               \"khaki4\"               \"lavender\"            \n[388] \"lavenderblush\"        \"lavenderblush1\"       \"lavenderblush2\"      \n[391] \"lavenderblush3\"       \"lavenderblush4\"       \"lawngreen\"           \n[394] \"lemonchiffon\"         \"lemonchiffon1\"        \"lemonchiffon2\"       \n[397] \"lemonchiffon3\"        \"lemonchiffon4\"        \"lightblue\"           \n[400] \"lightblue1\"           \"lightblue2\"           \"lightblue3\"          \n[403] \"lightblue4\"           \"lightcoral\"           \"lightcyan\"           \n[406] \"lightcyan1\"           \"lightcyan2\"           \"lightcyan3\"          \n[409] \"lightcyan4\"           \"lightgoldenrod\"       \"lightgoldenrod1\"     \n[412] \"lightgoldenrod2\"      \"lightgoldenrod3\"      \"lightgoldenrod4\"     \n[415] \"lightgoldenrodyellow\" \"lightgray\"            \"lightgreen\"          \n[418] \"lightgrey\"            \"lightpink\"            \"lightpink1\"          \n[421] \"lightpink2\"           \"lightpink3\"           \"lightpink4\"          \n[424] \"lightsalmon\"          \"lightsalmon1\"         \"lightsalmon2\"        \n[427] \"lightsalmon3\"         \"lightsalmon4\"         \"lightseagreen\"       \n[430] \"lightskyblue\"         \"lightskyblue1\"        \"lightskyblue2\"       \n[433] \"lightskyblue3\"        \"lightskyblue4\"        \"lightslateblue\"      \n[436] \"lightslategray\"       \"lightslategrey\"       \"lightsteelblue\"      \n[439] \"lightsteelblue1\"      \"lightsteelblue2\"      \"lightsteelblue3\"     \n[442] \"lightsteelblue4\"      \"lightyellow\"          \"lightyellow1\"        \n[445] \"lightyellow2\"         \"lightyellow3\"         \"lightyellow4\"        \n[448] \"limegreen\"            \"linen\"                \"magenta\"             \n[451] \"magenta1\"             \"magenta2\"             \"magenta3\"            \n[454] \"magenta4\"             \"maroon\"               \"maroon1\"             \n[457] \"maroon2\"              \"maroon3\"              \"maroon4\"             \n[460] \"mediumaquamarine\"     \"mediumblue\"           \"mediumorchid\"        \n[463] \"mediumorchid1\"        \"mediumorchid2\"        \"mediumorchid3\"       \n[466] \"mediumorchid4\"        \"mediumpurple\"         \"mediumpurple1\"       \n[469] \"mediumpurple2\"        \"mediumpurple3\"        \"mediumpurple4\"       \n[472] \"mediumseagreen\"       \"mediumslateblue\"      \"mediumspringgreen\"   \n[475] \"mediumturquoise\"      \"mediumvioletred\"      \"midnightblue\"        \n[478] \"mintcream\"            \"mistyrose\"            \"mistyrose1\"          \n[481] \"mistyrose2\"           \"mistyrose3\"           \"mistyrose4\"          \n[484] \"moccasin\"             \"navajowhite\"          \"navajowhite1\"        \n[487] \"navajowhite2\"         \"navajowhite3\"         \"navajowhite4\"        \n[490] \"navy\"                 \"navyblue\"             \"oldlace\"             \n[493] \"olivedrab\"            \"olivedrab1\"           \"olivedrab2\"          \n[496] \"olivedrab3\"           \"olivedrab4\"           \"orange\"              \n[499] \"orange1\"              \"orange2\"              \"orange3\"             \n[502] \"orange4\"              \"orangered\"            \"orangered1\"          \n[505] \"orangered2\"           \"orangered3\"           \"orangered4\"          \n[508] \"orchid\"               \"orchid1\"              \"orchid2\"             \n[511] \"orchid3\"              \"orchid4\"              \"palegoldenrod\"       \n[514] \"palegreen\"            \"palegreen1\"           \"palegreen2\"          \n[517] \"palegreen3\"           \"palegreen4\"           \"paleturquoise\"       \n[520] \"paleturquoise1\"       \"paleturquoise2\"       \"paleturquoise3\"      \n[523] \"paleturquoise4\"       \"palevioletred\"        \"palevioletred1\"      \n[526] \"palevioletred2\"       \"palevioletred3\"       \"palevioletred4\"      \n[529] \"papayawhip\"           \"peachpuff\"            \"peachpuff1\"          \n[532] \"peachpuff2\"           \"peachpuff3\"           \"peachpuff4\"          \n[535] \"peru\"                 \"pink\"                 \"pink1\"               \n[538] \"pink2\"                \"pink3\"                \"pink4\"               \n[541] \"plum\"                 \"plum1\"                \"plum2\"               \n[544] \"plum3\"                \"plum4\"                \"powderblue\"          \n[547] \"purple\"               \"purple1\"              \"purple2\"             \n[550] \"purple3\"              \"purple4\"              \"red\"                 \n[553] \"red1\"                 \"red2\"                 \"red3\"                \n[556] \"red4\"                 \"rosybrown\"            \"rosybrown1\"          \n[559] \"rosybrown2\"           \"rosybrown3\"           \"rosybrown4\"          \n[562] \"royalblue\"            \"royalblue1\"           \"royalblue2\"          \n[565] \"royalblue3\"           \"royalblue4\"           \"saddlebrown\"         \n[568] \"salmon\"               \"salmon1\"              \"salmon2\"             \n[571] \"salmon3\"              \"salmon4\"              \"sandybrown\"          \n[574] \"seagreen\"             \"seagreen1\"            \"seagreen2\"           \n[577] \"seagreen3\"            \"seagreen4\"            \"seashell\"            \n[580] \"seashell1\"            \"seashell2\"            \"seashell3\"           \n[583] \"seashell4\"            \"sienna\"               \"sienna1\"             \n[586] \"sienna2\"              \"sienna3\"              \"sienna4\"             \n[589] \"skyblue\"              \"skyblue1\"             \"skyblue2\"            \n[592] \"skyblue3\"             \"skyblue4\"             \"slateblue\"           \n[595] \"slateblue1\"           \"slateblue2\"           \"slateblue3\"          \n[598] \"slateblue4\"           \"slategray\"            \"slategray1\"          \n[601] \"slategray2\"           \"slategray3\"           \"slategray4\"          \n[604] \"slategrey\"            \"snow\"                 \"snow1\"               \n[607] \"snow2\"                \"snow3\"                \"snow4\"               \n[610] \"springgreen\"          \"springgreen1\"         \"springgreen2\"        \n[613] \"springgreen3\"         \"springgreen4\"         \"steelblue\"           \n[616] \"steelblue1\"           \"steelblue2\"           \"steelblue3\"          \n[619] \"steelblue4\"           \"tan\"                  \"tan1\"                \n[622] \"tan2\"                 \"tan3\"                 \"tan4\"                \n[625] \"thistle\"              \"thistle1\"             \"thistle2\"            \n[628] \"thistle3\"             \"thistle4\"             \"tomato\"              \n[631] \"tomato1\"              \"tomato2\"              \"tomato3\"             \n[634] \"tomato4\"              \"turquoise\"            \"turquoise1\"          \n[637] \"turquoise2\"           \"turquoise3\"           \"turquoise4\"          \n[640] \"violet\"               \"violetred\"            \"violetred1\"          \n[643] \"violetred2\"           \"violetred3\"           \"violetred4\"          \n[646] \"wheat\"                \"wheat1\"               \"wheat2\"              \n[649] \"wheat3\"               \"wheat4\"               \"whitesmoke\"          \n[652] \"yellow\"               \"yellow1\"              \"yellow2\"             \n[655] \"yellow3\"              \"yellow4\"              \"yellowgreen\"         \n\n\nThis was just an illustration of using the color ‚Äústeelblue‚Äù in a plot.\n\n```{r}\nplot(cars, col = \"steelblue\")\n```"
  },
  {
    "objectID": "class_notes/2023-01-12_Quarto/index.html",
    "href": "class_notes/2023-01-12_Quarto/index.html",
    "title": "Plan for Onboarding Day",
    "section": "",
    "text": "Follow Plan here: Onboarding"
  },
  {
    "objectID": "class_notes/2023-01-12_Quarto/index.html#rstudio-project-creation",
    "href": "class_notes/2023-01-12_Quarto/index.html#rstudio-project-creation",
    "title": "Plan for Onboarding Day",
    "section": "RStudio Project Creation",
    "text": "RStudio Project Creation\n\nGeneral RStudio Project Creation\nRStudio Project creation from Github Repository"
  },
  {
    "objectID": "class_notes/2023-01-12_Quarto/index.html#quarto-intro",
    "href": "class_notes/2023-01-12_Quarto/index.html#quarto-intro",
    "title": "Plan for Onboarding Day",
    "section": "Quarto Intro",
    "text": "Quarto Intro\n\n.qmd editing in the visual editor\n\nOpen Week 1 index.qmd.\n\nbasic formatting\n\nheaders\nitalics\nmonospace\nlinks\n\n\n\nyaml header\n\nLots of options: https://quarto.org/docs/reference/formats/html.html\ntitle:\nauthor:\ndate:\ntoc:\ndraft:\n\n\nthe _metadata file\nthe _quarto file\nCode chunks\n\n\n1+1\n\n[1] 2\n\n\nRender\nUnder the Build tab, clicking ‚ÄúRender Website‚Äù will render the whole website as a preview. The actual html pages etc are created in the _site folder by default."
  },
  {
    "objectID": "class_notes/2023-01-12_Quarto/index.html#visual-mode-goodies",
    "href": "class_notes/2023-01-12_Quarto/index.html#visual-mode-goodies",
    "title": "Plan for Onboarding Day",
    "section": "Visual Mode Goodies",
    "text": "Visual Mode Goodies\n\n\nForward slash / to bring up insert palette at the start of a new paragraph, or ‚åò+/ or CMD+/ for inline options.\n\ne.g.¬†images, tables, footnotes"
  },
  {
    "objectID": "class_notes/2023-01-12_Quarto/index.html#tricking-out-rstudio",
    "href": "class_notes/2023-01-12_Quarto/index.html#tricking-out-rstudio",
    "title": "Plan for Onboarding Day",
    "section": "Tricking out RStudio",
    "text": "Tricking out RStudio\nUnder Tools>Global Options there are a few things you might really want to customize, including\n\nAppearance: Will change the appearance and color themes of RStudio\nRMarkdown: Under the Citations tab, you can connect RStudio up to your Zotero"
  },
  {
    "objectID": "class_notes/2023-01-31_tidy-plot/index.html",
    "href": "class_notes/2023-01-31_tidy-plot/index.html",
    "title": "Tidying and Plotting",
    "section": "",
    "text": "library(tidyverse)\nlibrary(nasapower)\n\nGrabbing monthly temperature averages for Lexington. Untidy data.\n\nlex_temp <- \n  get_power(\n    community = \"ag\",\n    temporal_api = \"monthly\",\n    pars = \"T2M\",\n    dates = c(\"1985-01-01\", \"2021-12-31\"),\n    lonlat = c(-84.501640,  38.047989)\n  )\n\nUntidy because each row has 12 different observations (1 for each month). Column names JAN through DEC should be variables.\n\nlex_temp\n\n\n\n\n\n  \n\n\n\nPivoting from wide to long\n\nlex_temp |>\n  pivot_longer(\n    # which columns should go long?\n    cols = JAN:DEC,\n    # where should the column names go?\n    names_to = \"month\",\n    # where shoild the column values go?\n    values_to = \"temp\"\n  )"
  },
  {
    "objectID": "class_notes/2023-01-31_tidy-plot/index.html#getting-untidy-data",
    "href": "class_notes/2023-01-31_tidy-plot/index.html#getting-untidy-data",
    "title": "Tidying and Plotting",
    "section": "Getting untidy data",
    "text": "Getting untidy data\nExample untidy (linguistic!) data can be found in Joseph Casillas‚Äô package on github.\n\ninstall.packages(\"devtools\")\ndevtools::install_github(\"jvcasillas/untidydata\")\n\n\nlibrary(untidydata)\n\nVowel formant estimates for spanish vowels. The data column label follows good file naming protocol, but poor data column protocol. Three different variables smushed together into one:\n\nspeaker id\nspeaker gender\nvowel class\n\n\nspanish_vowels\n\n\n\n\n\n  \n\n\n\nThese three columns can be separated out with the tidyr::separate() function.\n\ntidy_vowels <-\n  spanish_vowels |>\n  separate(\n    # which column to separate\n    col = label,\n    # how to separate them\n    sep = \"-\",\n    # what to call the new columns\n    into = c(\"id\", \"gender\", \"vowel\")\n  )\n\n\ntidy_vowels"
  },
  {
    "objectID": "class_notes/2023-01-31_tidy-plot/index.html#plotting",
    "href": "class_notes/2023-01-31_tidy-plot/index.html#plotting",
    "title": "Tidying and Plotting",
    "section": "Plotting",
    "text": "Plotting\nMaking a ggplot vowel plot from tidy_vowels.\nggplot2 resources\n\nhttps://r4ds.hadley.nz/data-visualize.html\nhttps://ggplot2-book.org/\n\nThese plots are built by adding ‚Äúlayers‚Äù\nData Layer\n\nThe aes() function is used to map data variables to plot aesthetics.\n\n\ntidy_vowels |> \n  ggplot(aes(x = f2, y = f1))\n\n\n\n\nGeometry layer\n‚Äúgeometries‚Äù are the visual components of plots.\n\ntidy_vowels |>\n  ggplot(aes(x = f2, y = f1)) +\n    geom_point()\n\n\n\n\nWe can set certain visual components of geometries.\n\ntidy_vowels |>\n  ggplot(aes(x = f2, y = f1)) +\n    geom_point(\n      color = \"#BE3455\",\n      size = 4,\n      # alpha is transparency\n      alpha = 0.6,\n      shape = \"square\"\n    )\n\n\n\n\nWe can also map data to the visual components.\n\ntidy_vowels |>\n  ggplot(\n    aes(\n      x = f2, \n      y = f1,\n      color = vowel\n    )\n  ) +\n    geom_point()\n\n\n\n\nStatistic layers\nWe can add ‚Äústatistic‚Äù layers to plots as well.\n\ntidy_vowels |>\n  ggplot(\n    aes(\n      x = f2, \n      y = f1,\n      color = vowel\n    )\n  ) +\n    geom_point()+\n    # Doesn't really make sense\n    stat_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\ntidy_vowels |>\n  ggplot(\n    aes(\n      x = f2, \n      y = f1,\n      color = vowel\n    )\n  ) +\n    geom_point()+\n    stat_ellipse()\n\n\n\n\nScale layers\nWe can adjust the ‚Äúscales‚Äù of the spatial axes and other aesthetic mappings with scale layers.\n\n# this might need installing\nlibrary(khroma)\n\n\ntidy_vowels |>\n  ggplot(\n    aes(\n      x = f2, \n      y = f1,\n      color = vowel\n    )\n  ) +\n    geom_point()+\n    stat_ellipse()+\n    # reverse x and y\n    scale_y_continuous(trans = \"reverse\")+\n    scale_x_continuous(trans = \"reverse\")+\n    scale_color_vibrant()\n\n\n\n\nTitles\nThe ggplot2::labs() layer will do you.\n\ntidy_vowels |>\n  ggplot(\n    aes(\n      x = f2, \n      y = f1,\n      color = vowel\n    )\n  ) +\n    geom_point()+\n    stat_ellipse()+\n    # reverse x and y\n    scale_y_continuous(trans = \"reverse\")+\n    scale_x_continuous(trans = \"reverse\")+\n    scale_color_vibrant()+\n    labs(title = \"vowels\",\n         x = \"F2 (hz)\",\n         y = \"F1 (hz)\",\n         color = \"vowel\\nclass\")\n\n\n\n\nFaceting\nYou can make small multiples with ggplot2::facet_wrap() or ggplot2::facet_grid().\n\ntidy_vowels |>\n  ggplot(\n    aes(\n      x = f2, \n      y = f1,\n      color = vowel\n    )\n  ) +\n    geom_point()+\n    stat_ellipse()+\n    # reverse x and y\n    scale_y_continuous(trans = \"reverse\")+\n    scale_x_continuous(trans = \"reverse\")+\n    scale_color_vibrant()+\n    labs(title = \"vowels\",\n         x = \"F2 (hz)\",\n         y = \"F1 (hz)\",\n         color = \"vowel\\nclass\")+\n    facet_wrap(~gender)\n\n\n\n\nTheming\nggplot2 has a number of built in themes\n\ntidy_vowels |>\n  ggplot(\n    aes(\n      x = f2, \n      y = f1,\n      color = vowel\n    )\n  ) +\n    geom_point()+\n    stat_ellipse()+\n    # reverse x and y\n    scale_y_continuous(trans = \"reverse\")+\n    scale_x_continuous(trans = \"reverse\")+\n    scale_color_vibrant()+\n    labs(title = \"vowels\",\n         x = \"F2 (hz)\",\n         y = \"F1 (hz)\",\n         color = \"vowel\\nclass\")+\n    facet_wrap(~gender) +\n    theme_minimal()\n\n\n\n\nYou can get additional fine-grained control with ggplot2::theme()\n\ntidy_vowels |>\n  ggplot(\n    aes(\n      x = f2, \n      y = f1,\n      color = vowel\n    )\n  ) +\n    geom_point()+\n    stat_ellipse()+\n    # reverse x and y\n    scale_y_continuous(trans = \"reverse\")+\n    scale_x_continuous(trans = \"reverse\")+\n    scale_color_vibrant()+\n    labs(title = \"vowels\",\n         x = \"F2 (hz)\",\n         y = \"F1 (hz)\",\n         color = \"vowel\\nclass\")+\n    facet_wrap(~gender) +\n    theme_minimal() +\n    theme(\n      legend.position = \"top\",\n      aspect.ratio = 1\n      )\n\n\n\n\nCombining with tidy workflows\nTo label each vowel cluster with its vowel class, we need to calculate the F1 and F2 means for each vowel for each gender.\n\nvowel_means <- \n  tidy_vowels |>\n  group_by(vowel, gender) |>\n  summarise(f1= mean(f1), f2 = mean(f2))\n\n`summarise()` has grouped output by 'vowel'. You can override using the\n`.groups` argument.\n\n\nNow add a geom_label() layer on after the geom_point() layer.\n\ntidy_vowels |>\n  ggplot(\n    aes(\n      x = f2, \n      y = f1,\n      color = vowel\n    )\n  ) +\n    geom_point()+\n    geom_label(\n      data = vowel_means,\n      aes(label = vowel)\n    )+\n    stat_ellipse()+\n    # reverse x and y\n    scale_y_continuous(trans = \"reverse\")+\n    scale_x_continuous(trans = \"reverse\")+\n    scale_color_vibrant()+\n    labs(title = \"vowels\",\n         x = \"F2 (hz)\",\n         y = \"F1 (hz)\",\n         color = \"vowel\\nclass\")+\n    facet_wrap(~gender) +\n    theme_minimal() +\n    theme(\n      legend.position = \"top\",\n      aspect.ratio = 1\n      )\n\n\n\n\nStrictly speaking, the legend isn‚Äôt necessary anymore with the direct labels. I‚Äôll drop it with the guides() layer. I‚Äôve placed it after the scale_ layers, just for code clarity.\n\ntidy_vowels |>\n  ggplot(\n    aes(\n      x = f2, \n      y = f1,\n      color = vowel\n    )\n  ) +\n    geom_point()+\n    geom_label(\n      data = vowel_means,\n      aes(label = vowel)\n    )+\n    stat_ellipse()+\n    # reverse x and y\n    scale_y_continuous(trans = \"reverse\")+\n    scale_x_continuous(trans = \"reverse\")+\n    scale_color_vibrant()+\n    guides(color = \"none\")+\n    labs(title = \"vowels\",\n         x = \"F2 (hz)\",\n         y = \"F1 (hz)\",\n         color = \"vowel\\nclass\")+\n    facet_wrap(~gender) +\n    theme_minimal() +\n    theme(\n      aspect.ratio = 1\n      )"
  },
  {
    "objectID": "class_notes/2023-01-23_tidyverse/index.html",
    "href": "class_notes/2023-01-23_tidyverse/index.html",
    "title": "Starting with the tidyverse",
    "section": "",
    "text": "Let‚Äôs start by loading the tidyverse."
  },
  {
    "objectID": "class_notes/2023-01-23_tidyverse/index.html#tidyverse-functions-as-verbs",
    "href": "class_notes/2023-01-23_tidyverse/index.html#tidyverse-functions-as-verbs",
    "title": "Starting with the tidyverse",
    "section": "Tidyverse functions as verbs",
    "text": "Tidyverse functions as verbs\nMost tidyverse functions are written to be verbs, taje a data frame as their first argument, and also return a data frame.\n\n# a data frame\nmtcars <- as_tibble(mtcars)\nmtcars\n\n# A tibble: 32 √ó 11\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1  21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8  24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9  22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10  19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# ‚Ä¶ with 22 more rows\n\n\n\n# filter the dataframe to \n# only the rows with cyl==6\nfilter(mtcars, cyl == 6)\n\n# A tibble: 7 √ó 11\n    mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1  21       6  160    110  3.9   2.62  16.5     0     1     4     4\n2  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n3  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n4  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n5  19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n6  17.8     6  168.   123  3.92  3.44  18.9     1     0     4     4\n7  19.7     6  145    175  3.62  2.77  15.5     0     1     5     6\n\n\n\n# count how many rows \n# have these values of gears\ncount(mtcars, gear)\n\n# A tibble: 3 √ó 2\n   gear     n\n  <dbl> <int>\n1     3    15\n2     4    12\n3     5     5"
  },
  {
    "objectID": "class_notes/2023-01-23_tidyverse/index.html#piping",
    "href": "class_notes/2023-01-23_tidyverse/index.html#piping",
    "title": "Starting with the tidyverse",
    "section": "Piping",
    "text": "Piping\nSince tidyverse functions take data frames as input, and produce data frames as output, you might want to combine them.\nWhat are the counts of gear for cars with cyl==6?\n\ncount(\n  filter(\n    mtcars, \n    cyl == 6\n    ), \n  gear\n  )\n\n# A tibble: 3 √ó 2\n   gear     n\n  <dbl> <int>\n1     3     2\n2     4     4\n3     5     1\n\n\nA problem here is that you have to write, and read your functions inside out. Wouldn‚Äôt it be great if we could write code that looks like:\n\nFirst take the mtcars data, and then filter it by cyl==6, then get the count of gears.\n\nThat‚Äôs where the pipe |> comes in. The pipe takes everything to its left, and inserts it as the first argument to the function on its right.\n\n# this\nmtcars |> filter(cyl == 6)\n\n# is equivalent to this\nfilter(mtcars, cyl == 6)\n\nThis lets us chain tidyverse verbs together.\n\nmtcars |> \n  filter(cyl == 6) |> \n  count(gear)\n\n# A tibble: 3 √ó 2\n   gear     n\n  <dbl> <int>\n1     3     2\n2     4     4\n3     5     1\n\n\n\n\n\n\n\n\nWork it out\n\n\n\nThe dataframe starwars contains demographic and personal data for many characters from the Star Wars universe. Using dplyr verbs like\n\nfilter()\ncount()\narrange()\nslice()\nselect()\n\n\nFind out which planet is the most common homeworld for humans.\nFind out who was the tallest Droid."
  },
  {
    "objectID": "class_notes/2023-01-23_tidyverse/index.html#grouping-and-summarizing",
    "href": "class_notes/2023-01-23_tidyverse/index.html#grouping-and-summarizing",
    "title": "Starting with the tidyverse",
    "section": "Grouping and summarizing",
    "text": "Grouping and summarizing\nTo find out average horsepower across all of the cars in mtcars, we can use summarise()\n\nmtcars |> \n  summarise(hp = mean(hp))\n\n# A tibble: 1 √ó 1\n     hp\n  <dbl>\n1  147.\n\n\nIf we wanted to find out the average horsepower by the number of cylinders, we can group_by() and then summarise().\n\nmtcars |> \n  group_by(cyl) |> \n  summarise(hp = mean(hp))\n\n# A tibble: 3 √ó 2\n    cyl    hp\n  <dbl> <dbl>\n1     4  82.6\n2     6 122. \n3     8 209."
  },
  {
    "objectID": "class_notes/2023-01-23_tidyverse/index.html#mutating",
    "href": "class_notes/2023-01-23_tidyverse/index.html#mutating",
    "title": "Starting with the tidyverse",
    "section": "Mutating",
    "text": "Mutating\nTo add new columns to a data frame, we can use mutate(). Inside of mutate, we can make reference to any column in the dataframe.\n\n## horsepower by cylinder?\nmtcars |> \n  mutate(hp_by_cyl = hp/cyl)\n\n# A tibble: 32 √ó 12\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb hp_by_cyl\n   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>     <dbl>\n 1  21       6  160    110  3.9   2.62  16.5     0     1     4     4      18.3\n 2  21       6  160    110  3.9   2.88  17.0     0     1     4     4      18.3\n 3  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1      23.2\n 4  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1      18.3\n 5  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2      21.9\n 6  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1      17.5\n 7  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4      30.6\n 8  24.4     4  147.    62  3.69  3.19  20       1     0     4     2      15.5\n 9  22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2      23.8\n10  19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4      20.5\n# ‚Ä¶ with 22 more rows\n\n\n\n\n\n\n\n\nWork it out\n\n\n\nThis will load all tokens of ‚Äúuh‚Äù and ‚Äúum‚Äù from the Philadelphia Neighborhood Corpus.\n\num <- read_tsv(\"https://bit.ly/3JdeSbx\")\n\nRows: 26060 Columns: 14\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \"\\t\"\nchr  (3): word, next_seg, idstring\ndbl (11): start_time, end_time, vowel_start, vowel_end, nasal_start, nasal_e...\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe column word codes whether it was ‚Äúum‚Äù or ‚Äúuh‚Äù or some combo that was spoken. Other important columns are\n\nstart_time, end_time: the start and end times for the whole word\nvowel_start, vowel_end: The start and end time of the vowel in the word.\nnasal_start, nasal_end: The start and end times of the nasal, for the word UM.\nnext_seg: the transcription of the following segment. \"sp\" means ‚Äúpause‚Äù\nnext_seg_start, next_seg_end the start and end times of the following segment\n\n\num\n\n# A tibble: 26,060 √ó 14\n   word  start‚Ä¶¬π end_t‚Ä¶¬≤ vowel‚Ä¶¬≥ vowel‚Ä¶‚Å¥ nasal‚Ä¶‚Åµ nasal‚Ä¶‚Å∂ next_‚Ä¶‚Å∑ next_‚Ä¶‚Å∏ next_‚Ä¶‚Åπ\n   <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>     <dbl>   <dbl>\n 1 UH       24.4    24.7    24.4    24.7    NA      NA   S          24.7    24.9\n 2 UH       35.0    35.2    35.0    35.2    NA      NA   F          35.2    35.4\n 3 UM       37.9    38.3    37.9    38.1    38.1    38.3 sp         38.3    38.4\n 4 UH       44.5    44.7    44.5    44.7    NA      NA   DH         44.7    44.7\n 5 UH       57.6    57.8    57.6    57.8    NA      NA   AY1        57.8    57.9\n 6 UH       62.3    62.5    62.3    62.5    NA      NA   sp         62.5    63.0\n 7 UH       73.9    74.2    73.9    74.2    NA      NA   sp         74.2    75.0\n 8 UH       75.1    75.4    75.1    75.4    NA      NA   sp         75.4    75.7\n 9 UM       81.6    82.0    81.6    81.8    81.8    82.0 sp         82.0    84.0\n10 UH       92.6    92.9    92.6    92.9    NA      NA   sp         92.9    93.4\n# ‚Ä¶ with 26,050 more rows, 4 more variables: chunk_start <dbl>,\n#   chunk_end <dbl>, nwords <dbl>, idstring <chr>, and abbreviated variable\n#   names ¬π‚Äãstart_time, ¬≤‚Äãend_time, ¬≥‚Äãvowel_start, ‚Å¥‚Äãvowel_end, ‚Åµ‚Äãnasal_start,\n#   ‚Å∂‚Äãnasal_end, ‚Å∑‚Äãnext_seg, ‚Å∏‚Äãnext_seg_start, ‚Åπ‚Äãnext_seg_end\n\n\nUsing dplyr verbs like\n\nmutate()\ngroup_by()\nsummarise()\n\n\nFigure out the average duration of the vowel for each kind of word.\nFigure out the average duration of the vowel for each kind of word when the following segment is a pause versus when it isn‚Äôt."
  },
  {
    "objectID": "class_notes/2023-01-17_osf-data/index.html",
    "href": "class_notes/2023-01-17_osf-data/index.html",
    "title": "Downloading OSF Data",
    "section": "",
    "text": "The data for winter‚Äôs Statistics for Linguistics textbook is all available on the Open Science Framework at https://osf.io/34mq9/ You can download the files as you need them and upload them into your blog files, or you can download the whole thing at once with this quarto notebook and the osfr package.\nI‚Äôm effectively just running through their sample documentation from the about page."
  },
  {
    "objectID": "class_notes/2023-01-17_osf-data/index.html#step-1---install-osfr-and-load-it",
    "href": "class_notes/2023-01-17_osf-data/index.html#step-1---install-osfr-and-load-it",
    "title": "Downloading OSF Data",
    "section": "Step 1 - Install osfr and load it",
    "text": "Step 1 - Install osfr and load it\nThis will check to see of osfr is installed. If it is, it will load it. If not, it will install it, then load it. This may start printing out scary looking things like g++ -std=gnu++14 -I\"/usr/share/R/include\" and so forth. That is ok.\n\nosfr_exists <- require(\"osfr\")\n\nLoading required package: osfr\n\nif(!osfr_exists){\n  install.packages(\"osfr\")\n  library(osfr)\n}"
  },
  {
    "objectID": "class_notes/2023-01-17_osf-data/index.html#step-2---download-the-data",
    "href": "class_notes/2023-01-17_osf-data/index.html#step-2---download-the-data",
    "title": "Downloading OSF Data",
    "section": "Step 2 - Download the data",
    "text": "Step 2 - Download the data\nThe little string of letters and numbers comes from the osf link. I‚Äôve included some if()s in there to be defensive, just in case you re-run the code so you won‚Äôt accidentally delete or overwrite anything.\n\n# I'm just being defensive here,\n# in case you've run the script before.\ndata_exists <- dir.exists(\"data\")\nif(!data_exists){\n  dir.create(path = \"data\")\n}\n\n\ndata_files <- list.files(\"data\")\nif(length(data_files) != 17){\n  osf_retrieve_node('34mq9') |> \n    osf_ls_files(\n      \"materials/data\", \n      n_max = Inf\n    ) |> \n    osf_download(\n      path = \"data\",\n      conflicts = \"skip\"\n    )\n}"
  },
  {
    "objectID": "class_notes/2023-01-17_osf-data/index.html#step-3---load-the-data-into-your-blog-post.",
    "href": "class_notes/2023-01-17_osf-data/index.html#step-3---load-the-data-into-your-blog-post.",
    "title": "Downloading OSF Data",
    "section": "Step 3 - Load the data into your blog post.",
    "text": "Step 3 - Load the data into your blog post.\nThere are two ways to go about loading the data into a quarto notebook for your work-through blog post.\nWay 1\nI‚Äôve assumed you‚Äôve run the download_data.qmd code from the main workthrough blog directory. So, from any given blog post in posts/XX_chapter/index.qmd file, you‚Äôd need to type\n\nnettle_df <- read.csv(\"../../data/nettle_1999_climate.csv\")\n\nWay 2\nIn the file browser pane in RStudio, if you navigate to the data directory, click on the ‚Äú‚öôÔ∏è More‚Äù drop down menu. Then select Copy Folder Path to Clipboard. For me, this copies ~/work_through_blog/data to the clipboard. You can then use this inside read.csv() like so:\n\nnettle_df <- read.csv(\"~/work_through_blog/data/nettle_1999_climate.csv\")"
  },
  {
    "objectID": "class_notes/2023-01-17_RLang/index.html",
    "href": "class_notes/2023-01-17_RLang/index.html",
    "title": "Basics of R Syntax",
    "section": "",
    "text": "To run R code in a Quarto notebook, you need to insert a ‚Äúcode chunk‚Äù. In visual editor mode, you can do that by typing the forward slash (/) and start typing in ‚ÄúR Code Chunk‚Äù. In the source editor mode, you have to have a line with ```{r} (three ‚Äúbackticks‚Äù followed by ‚Äúr‚Äù in curly braces), then a few blank lines followed by another ```\n\n```{r}\n1+1\n```\n\n[1] 2\n\n\nTo actually run the code, you can either click on the green play button, or press the appropriate hotkey for your system (COMMAND+RETURN on a mac, CTRL+ENTER on windows)."
  },
  {
    "objectID": "class_notes/2023-01-17_RLang/index.html#mathematical-operations",
    "href": "class_notes/2023-01-17_RLang/index.html#mathematical-operations",
    "title": "Basics of R Syntax",
    "section": "Mathematical Operations",
    "text": "Mathematical Operations\nAddition\n\n1 + 4\n\n[1] 5\n\n\nSubtraction\n\n1 - 4\n\n[1] -3\n\n\nMultiplication\n\n5 * 4\n\n[1] 20\n\n\nDivision\n\n5 / 4\n\n[1] 1.25\n\n\nExponentiation\n\n5 ^ 4\n\n[1] 625\n\n\nOrders of Operation\nHonestly, instead of gambling on how R may or may not interpret PEMDAS, just add parentheses ( ) around every operation in the order you want it to happen.\n\n(5 ^ (2 * 2)) / 6\n\n[1] 104.1667"
  },
  {
    "objectID": "class_notes/2023-01-17_RLang/index.html#assignment",
    "href": "class_notes/2023-01-17_RLang/index.html#assignment",
    "title": "Basics of R Syntax",
    "section": "Assignment",
    "text": "Assignment\nTo assign values to a variable in R, you can use either <- or ->. Most style guides shun ->, but I actually wind up using it a lot.\n\nmy_variable <- 4 * 5\nprint(my_variable)\n\n[1] 20\n\n\n\nmy_variable / 2\n\n[1] 10"
  },
  {
    "objectID": "class_notes/2023-01-17_RLang/index.html#data-types",
    "href": "class_notes/2023-01-17_RLang/index.html#data-types",
    "title": "Basics of R Syntax",
    "section": "Data Types",
    "text": "Data Types\nNumeric\nWhen using a number in R, we can only use digits and dots (.). If we try to enter ‚Äúone hundred thousand‚Äù with a comma separator, we‚Äôll get an error.\n\nbig_number <- 100,000\n\nError: <text>:1:18: unexpected ','\n1: big_number <- 100,\n                     ^\n\n\nWe also can‚Äôt use any percent signs (%) or currency symbols ($, ¬£, ‚Ç¨)\nCharacters\nWhen we type in text without any quotes, R will assume it‚Äôs a variable or function that‚Äôs already been defined and go looking for it.\n\nlarge <- 100000\nlarge\n\n[1] 1e+05\n\n\nIf the variable hasn‚Äôt been created already, we‚Äôll get an error.\n\nsmall\n\nError in eval(expr, envir, enclos): object 'small' not found\n\n\nIf we enter text inside of quotation marks, either single quotes ' or double quotes \", R will instead treat the text as a value that we could, for example, assign to a variable, or just print out.\n\n\"small\"\n\n[1] \"small\"\n\n\n\ntiny_synonym <- \"small\"\ntiny_synonym\n\n[1] \"small\"\n\n\n\n\n\n\n\n\nCommon Error\n\n\n\nYou will often get confused about this and get the Error: object '' not found message. Even if you do this for 15 years, you will still sometimes enter plain text when you meant to put it in quotes, and put text in quotes you meant to enter without. It‚Äôs always annoying, but doesn‚Äôt mean you‚Äôre bad at doing this.\n\n\nLogical\nThere are two specialized values that you could call ‚ÄúTrue/False‚Äù or ‚ÄúLogical‚Äù or ‚ÄúBoolean‚Äù values\n\n# fullnames\nTRUE\n\n[1] TRUE\n\nFALSE\n\n[1] FALSE\n\n\n\n# Short Forms\nT\n\n[1] TRUE\n\nF\n\n[1] FALSE\n\n\nThese are often created using logical comparisons\n\nlarge  <- 100000\nmedium <-    600\n\nlarge < medium\n\n[1] FALSE\n\n\n\nshort_word <- \"to\"\n\nnchar(short_word) == 2\n\n[1] TRUE\n\n\nNA\nWhen you have a missing value, that‚Äôs given a special NA value.\n\nnumbers <- c(1, NA, 5)\nnumbers\n\n[1]  1 NA  5"
  },
  {
    "objectID": "class_notes/2023-01-17_RLang/index.html#vectors",
    "href": "class_notes/2023-01-17_RLang/index.html#vectors",
    "title": "Basics of R Syntax",
    "section": "Vectors",
    "text": "Vectors\nVectors are basically 1 dimensional lists of values.1 You can have numeric, character or logical vectors in R, but you can‚Äôt mix types. One way to create vectors is with the c() (for concatenate) function. There needs to be a comma , between every value that you add to a vector.\n\ndigital_words <- c(\n  \"-dle\",\n  \"BFFR\",\n  \"chief twit\",\n  \"chronically online\",\n  \"crypto rug pull\",\n  \"touch grass\",\n  \"-verse\"\n)\nprint(digital_words)\n\n[1] \"-dle\"               \"BFFR\"               \"chief twit\"        \n[4] \"chronically online\" \"crypto rug pull\"    \"touch grass\"       \n[7] \"-verse\"            \n\n\n\ndigital_word_votes <- c(\n  84,\n  14,\n  4,\n  30,\n  8,\n  64,\n  8\n)\nprint(digital_word_votes)\n\n[1] 84 14  4 30  8 64  8\n\n\nYou can also create vectors of sequential vectors with the : operator.\n\n1:10\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\n\nMore vector creating possibilities\nThere are a lot of functions for creating vectors.\n\nseq(from = 1, to = 5, length = 10)\n\n [1] 1.000000 1.444444 1.888889 2.333333 2.777778 3.222222 3.666667 4.111111\n [9] 4.555556 5.000000\n\n\n\nseq_along(digital_words)\n\n[1] 1 2 3 4 5 6 7\n\n\n\nrep(c(\"a\", \"b\"), times = 3)\n\n[1] \"a\" \"b\" \"a\" \"b\" \"a\" \"b\"\n\n\n\nrep(c(\"a\", \"b\"), each = 3)\n\n[1] \"a\" \"a\" \"a\" \"b\" \"b\" \"b\"\n\n\nVector Arithmetic\nYou can do arithmetic on a whole vector of numbers. digital_word_votes is a vector of how many votes each word got. We can get the sum like so:\n\ntotal_votes <- sum(digital_word_votes)\ntotal_votes\n\n[1] 212\n\n\nThen, we can convert those vote counts to proportions by dividing them by the total.\n\ndigital_word_votes / total_votes\n\n[1] 0.39622642 0.06603774 0.01886792 0.14150943 0.03773585 0.30188679 0.03773585\n\n\nAnd we can convert that to percentages by multiplying by 100.\n\n(digital_word_votes / total_votes) * 100\n\n[1] 39.622642  6.603774  1.886792 14.150943  3.773585 30.188679  3.773585"
  },
  {
    "objectID": "class_notes/2023-01-17_RLang/index.html#indexing",
    "href": "class_notes/2023-01-17_RLang/index.html#indexing",
    "title": "Basics of R Syntax",
    "section": "Indexing",
    "text": "Indexing\nIf you‚Äôve never programmed before, this part will make sense, and if you haven‚Äôt programmed before, this part will be confusing.\nIf you have a vector, and you want to get the first value from it, you put square brackets [] after the variable name, and put 1 inside.\n\nprint(digital_words)\n\n[1] \"-dle\"               \"BFFR\"               \"chief twit\"        \n[4] \"chronically online\" \"crypto rug pull\"    \"touch grass\"       \n[7] \"-verse\"            \n\ndigital_words[1]\n\n[1] \"-dle\"\n\n\nIf you want a range of values from a vector, you can give it a vector of numeric indices.\n\ndigital_words[2:5]\n\n[1] \"BFFR\"               \"chief twit\"         \"chronically online\"\n[4] \"crypto rug pull\"   \n\n\nLogical Indexing\nAlso really useful is the ability to do logical indexing. For example, if we wanted to see which digital words got ten or fewer votes, we can do\n\ndigital_word_votes <= 10\n\n[1] FALSE FALSE  TRUE FALSE  TRUE FALSE  TRUE\n\n\nWe can use this sequence of TRUE and FALSE values to get the actual words from the digital_words vector.\n\ndigital_words[digital_word_votes <= 10]\n\n[1] \"chief twit\"      \"crypto rug pull\" \"-verse\""
  },
  {
    "objectID": "class_notes/2023-01-17_RLang/index.html#data-frames",
    "href": "class_notes/2023-01-17_RLang/index.html#data-frames",
    "title": "Basics of R Syntax",
    "section": "Data Frames",
    "text": "Data Frames\nThe most common kind of data structure we‚Äôre going to be working with are Data Frames. These are two dimensional structures with rows and columns. The data types within each column all need to be the same.\n\nword_df <- data.frame(\n  type = \"digital\",\n  word = digital_words,\n  votes = digital_word_votes  \n)\nprint(word_df)\n\n     type               word votes\n1 digital               -dle    84\n2 digital               BFFR    14\n3 digital         chief twit     4\n4 digital chronically online    30\n5 digital    crypto rug pull     8\n6 digital        touch grass    64\n7 digital             -verse     8\n\n\nNavigating data frames\nTo navigate data frames, there are a few handy functions. First, in RStudio you can launch a viewer with View()\n\nView(word_df)\n\nKeeping things inside the Quarto notebook, other useful functions are summary(), nrow(), ncol() and colnames().\n\nsummary(word_df)\n\n     type               word               votes      \n Length:7           Length:7           Min.   : 4.00  \n Class :character   Class :character   1st Qu.: 8.00  \n Mode  :character   Mode  :character   Median :14.00  \n                                       Mean   :30.29  \n                                       3rd Qu.:47.00  \n                                       Max.   :84.00  \n\nnrow(word_df)\n\n[1] 7\n\nncol(word_df)\n\n[1] 3\n\ncolnames(word_df)\n\n[1] \"type\"  \"word\"  \"votes\"\n\n\nIndexing Data Frames\nTo get all of the data from a single column of a data frame, we can put $ after the data frame variable name, then the name of the column.\n\nword_df$word\n\n[1] \"-dle\"               \"BFFR\"               \"chief twit\"        \n[4] \"chronically online\" \"crypto rug pull\"    \"touch grass\"       \n[7] \"-verse\"            \n\n\nWe‚Äôre going to have more, interesting ways to get specific rows from a data frame later on in the course, but for now if you want to subset just the rows that have 10 or fewer votes, we can use subset.\n\nsubset(word_df, votes <= 10)\n\n     type            word votes\n3 digital      chief twit     4\n5 digital crypto rug pull     8\n7 digital          -verse     8\n\n\n\nPipe Preview\nThe ‚Äúpipe‚Äù (|>) is going to play a big role in our R workflow. What it does is take whatever is on its left hand side and inserts it as the first argument to the function on the left hand side. Here‚Äôs a preview.\n\nword_df |> \n  subset(votes <= 10)\n\n     type            word votes\n3 digital      chief twit     4\n5 digital crypto rug pull     8\n7 digital          -verse     8"
  },
  {
    "objectID": "class_notes/2023-01-17_RLang/index.html#packages",
    "href": "class_notes/2023-01-17_RLang/index.html#packages",
    "title": "Basics of R Syntax",
    "section": "Packages",
    "text": "Packages\nPackages get installed once with install.pacakges()\n\n# Only needs to be run once ever, or when updating\ninstall.packages(\"tidyverse\")\n\nBut they need to be loaded every time with library()\n\n# Needs to be run every time\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 1.3.2 ‚îÄ‚îÄ\n‚úî ggplot2 3.4.0      ‚úî purrr   1.0.0 \n‚úî tibble  3.1.8      ‚úî dplyr   1.0.10\n‚úî tidyr   1.2.1      ‚úî stringr 1.4.1 \n‚úî readr   2.1.3      ‚úî forcats 0.5.2 \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n\n\nIf you try to load a package that you haven‚Äôt installed yet, you‚Äôll get this error:\n\nlibrary(fake_library)\n\nError in library(fake_library): there is no package called 'fake_library'"
  },
  {
    "objectID": "class_notes/2023-01-12_gh/index.html",
    "href": "class_notes/2023-01-12_gh/index.html",
    "title": "Github Onboarding with RStudio",
    "section": "",
    "text": "Instruction boxes with  should be done on github, and instruction boxes with  should be done in RStudio."
  },
  {
    "objectID": "class_notes/2023-01-12_gh/index.html#step-1-create-a-github-account",
    "href": "class_notes/2023-01-12_gh/index.html#step-1-create-a-github-account",
    "title": "Github Onboarding with RStudio",
    "section": "Step 1: Create a Github Account",
    "text": "Step 1: Create a Github Account\nGo over to Github and create a free account.\n\n\n\n\n\n\n\n\n\n\n\nGo To\n\nhttps://github.com/\n\n\n\n\nAs suggested in Happy Git Chapter 4, it would make sense to register an account username that aligns with your professional identity.\nAfter you‚Äôve created your free account, if you are affiliated with a university, I would also suggest applying for the education benefits here: https://education.github.com/. There are a few nice, but not mandatory, perks."
  },
  {
    "objectID": "class_notes/2023-01-12_gh/index.html#step-2-configure-git-in-rstudio",
    "href": "class_notes/2023-01-12_gh/index.html#step-2-configure-git-in-rstudio",
    "title": "Github Onboarding with RStudio",
    "section": "Step 2: Configure Git in RStudio",
    "text": "Step 2: Configure Git in RStudio\nNow, you need to tell Git a little bit about yourself on the computer/server you‚Äôre using RStudio on.\n\n\n\n\n\n\n\n\n\n\n\nGo To\n\nWherever you are using RStudio ( could be Posit Workbench, Posit Cloud, RStudio Server, or RStudio Desktop)\n\nThen Go To\n\nThe Console (a.k.a the R Prompt)\n\n\n\n\n\n\nThe Console in RStudio is here.\n\n\nNext, we need to tell the local version of Git who you are, specifically your username (which should match your Github username) and your email address (which should match the email address you registered for Github with).\n\n\n\n\n\n\n, \n\n\n\nIn the code below, USERNAME should be replaced with your Github username and EMAIL should be replaced with the email you registered your github account with.\n\n\n\nRun this in the R Console:\n\nsystem('git config --global user.name \"USERNAME\"')\nsystem('git config --global user.email \"EMAIL\"')"
  },
  {
    "objectID": "class_notes/2023-01-12_gh/index.html#step-3-configure-rstudio-to-communicate-with-github",
    "href": "class_notes/2023-01-12_gh/index.html#step-3-configure-rstudio-to-communicate-with-github",
    "title": "Github Onboarding with RStudio",
    "section": "Step 3: Configure RStudio to Communicate with Github",
    "text": "Step 3: Configure RStudio to Communicate with Github\nIn order to be able to push commits from RStudio to Github, you‚Äôll need to set up secure communication between wherever you are using RStudio and Github. I‚Äôll walk you through how to do this with SSH credentials. (See also Happy Git with R for personal access tokens via HTTPS).\nRStudio Configuration\n\n\n\n\n\n\n\n\n\n\n\nGo To:\n\nThe Tools menu, then Global Options\n\n\n\n\n\n\n\nThen Go To:\n\nGit/SVN from the left hand side option selector. Its icon is a cardboard box\n\n\n\n\n\n\n\nThen Go To\n\nCreate SSH Key\n\n\n\n\n\n\n\nThen\n\nThe default options should be fine to use. The passphrase here is for the ssh key. It should not be your Github password, or the password for logging into Posit Workbench or Posit Cloud. Once you‚Äôre ready, click Create.\n\nThen\n\nAfter creating the SSH key, you should see the option ‚ÄúView Public Key‚Äù. Click on it, and copy the text that appears.\n\n\n\n\nThis concludes everything necessary on the RStudio side of things. You should probably keep the session open so that you can come back to re-copy your public key.\nGithub Configuration\nNow, you‚Äôll need to go over to github to add the public key to your profile.\n\n\n\n\n\n\n\n\n\n\n\nGo To\n\nYour Github Profile Settings\n\n\n\n\n\n\n\nThen Go To\n\nSSH and GPG keys from the left side menu\n\n\n\n\n\n\n\nThen\n\nClick on the New SSH key button\n\n\n\n\n\n\n\nThen\n\nGive this key an informative name so you can remember which computer it‚Äôs coming from.\n\nThen\n\nPaste the text you copied from RStudio into the Key box and click Add SSH Key."
  },
  {
    "objectID": "class_notes/2023-01-12_gh/index.html#configured",
    "href": "class_notes/2023-01-12_gh/index.html#configured",
    "title": "Github Onboarding with RStudio",
    "section": "Configured",
    "text": "Configured\nNow, wherever you are using RStudio from should be able to push commits to your Github account."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Quantitative Methods in Linguistics",
    "section": "",
    "text": "This is the course website for Lin611: Quantitative Methods in Linguistics, taught in the Spring semester of 2023.\n\n\n\n\n\nNotes from in-class will be listed below. Other important information:\n\nPlease read the syllabus\nThe course textbook is Winter, B. (2019). Statistics for linguists: An introduction using R. Routledge. ISBN 978-1-138-05608-4\nKeep an eye on the course Canvas Shell for announcements and assignments.\n\n\n\n\n\n\n\n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\nTidy Vowel Normalization\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 2, 2023\n\n\nJosef Fruehwald\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTidying and Plotting\n\n\n\n\n\n\n\n\n\n\n\n\nJan 31, 2023\n\n\nJosef Fruehwald\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nContinuing with the tidyverse\n\n\n\n\n\n\n\n\n\n\n\n\nJan 26, 2023\n\n\nJosef Fruehwald\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStarting with the tidyverse\n\n\n\n\n\n\n\n\n\n\n\n\nJan 24, 2023\n\n\nJosef Fruehwald\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDownloading OSF Data\n\n\n\n\n\n\n\n\n\n\n\n\nJan 17, 2023\n\n\nJosef Fruehwald\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBasics of R Syntax\n\n\n\n\n\n\n\n\n\n\n\n\nJan 17, 2023\n\n\nJosef Fruehwald\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlan for Onboarding Day\n\n\n\n\n\n\n\n\n\n\n\n\nJan 12, 2023\n\n\nJosef Fruehwald\n\n\n\n\n\n\n  \n\n\n\n\nGithub Onboarding with RStudio\n\n\n\n\n\n\n\n\n\n\n\n\nJan 12, 2023\n\n\nJosef Fruehwald\n\n\n\n\n\n\n  \n\n\n\n\nWelcome Day\n\n\n\n\n\n\n\n\n\n\n\n\nJan 10, 2023\n\n\nJosef Fruehwald\n\n\n\n\n\n\nNo matching items\n\nReuseCC-BY-SA 4.0"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Lin611-001: Quantitative Methods in Linguistics",
    "section": "",
    "text": "Syllabus pdf"
  },
  {
    "objectID": "syllabus.html#key-info",
    "href": "syllabus.html#key-info",
    "title": "Lin611-001: Quantitative Methods in Linguistics",
    "section": "1 Key info",
    "text": "1 Key info\n\n\n\nWhere and When\n\n\n\nWhere:\nFunkhouser, 307B\n\n\nWhen:\nTuesdays & Thursdays, 12:30 : 13:45\n\n\n\n\n\nInstructor\n\n\n\n\nDr.¬†Josef Fruehwald\n\n\nemail:\njosef.fruehwald@uky.edu\n\n\noffice hours:\nMondays, 14:00 - 15:00\n\n\noffice location:\nPOT 1671"
  },
  {
    "objectID": "syllabus.html#course-at-a-glance",
    "href": "syllabus.html#course-at-a-glance",
    "title": "Lin611-001: Quantitative Methods in Linguistics",
    "section": "2 Course at a Glance",
    "text": "2 Course at a Glance\n\nWhat you‚Äôll learn:\n\nthe basics of statistical reasoning, linear modelling, data organization & visualization, R\n\nWhat you‚Äôll do:\n\nin-class exercises, a textbook work-through ‚Äúblog‚Äù, a midterm project, a final project.\n\nWhat you‚Äôll need:\n\nthe course textbook, a computing device with a physical keyboard\n\nThe final-est deadline\n\nThursday, May 4\n\n\n\nAdd to Calendar\n\n\n\nAttendance Policy\n\nAttendance is crucial for successful completion of the course, but there are no grade penalties.\n\nLate Work Policy\n\n2 day penalty free grace period on all assignments, 5% flat penalty afterwards. See Late Submissions and Re-submissions"
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "Lin611-001: Quantitative Methods in Linguistics",
    "section": "3 Course Description",
    "text": "3 Course Description\nIn recent decades, there has been a strong ‚Äúquantitative turn‚Äù in linguistics. Quantitative methods, including statistical analysis, have always been fixtures in some subfields, but there are now few areas of linguistic inquiry where they are completely absent. As a graduate course in quantitative methods, the goals of this course are to help you establish baseline statistical reasoning, and to provide practical experience in data (re)organization and statistical model building. We will be focusing our attention on the most common variety of statistical models (linear models and their generalizations) in the most commonly used programming language (R)."
  },
  {
    "objectID": "syllabus.html#learning-outcomes",
    "href": "syllabus.html#learning-outcomes",
    "title": "Lin611-001: Quantitative Methods in Linguistics",
    "section": "4 Learning Outcomes",
    "text": "4 Learning Outcomes\nAfter attending class meetings and completion of the coursework, students should be able to\n\nidentify appropriate quantitative analysis procedures for diverse data sets.\norganize data sets tidily\nre-organize untidy data sets in R\ngenerate exploratory data visualizations\nspecify and fit linear or generalized linear models in R\nreport the meaningful results of a statistical model"
  },
  {
    "objectID": "syllabus.html#course-materials",
    "href": "syllabus.html#course-materials",
    "title": "Lin611-001: Quantitative Methods in Linguistics",
    "section": "5 Course Materials",
    "text": "5 Course Materials\n\nRequired:\nWinter, B. (2019). Statistics for linguists: An introduction using R. Routledge. ISBN 978-1138056091.\n\n\nRecommended:\nWickham, H & G. Grolemund (2022*) R for Data Science https://r4ds.had.co.nz/."
  },
  {
    "objectID": "syllabus.html#course-technology",
    "href": "syllabus.html#course-technology",
    "title": "Lin611-001: Quantitative Methods in Linguistics",
    "section": "6 Course Technology",
    "text": "6 Course Technology\n\nR/RStudio\nWe‚Äôll be learning how to implement our analyses in the R programming language, specifically using the RStudio IDE. You can install and configure RStudio on your own computer that you bring to class. You will also have access to RStudio Workbench hosted by the College of Arts & Sciences at https://rstudio.as.uky.edu/. You can log in with your LinkBlue credentials.\n\n\nQuarto/Quarto Notebooks\nQuarto is a program built into RStudio that takes source documents written in Markdown and R, and renders them into various output document formats, including html and pdf. This program is included in RStudio, and won‚Äôt require additional download or installation.\n\n\nGit/Github\nGit is a ‚ÄúVersion Control System‚Äù that lets you keep track of changes on software projects. Github is a service that allows online hosting of Git projects. You will need to create a free a Github account for the course.\n\n\nCanvas\nCanvas will be used to make course announcements, and to set & submit assignments."
  },
  {
    "objectID": "syllabus.html#communications",
    "href": "syllabus.html#communications",
    "title": "Lin611-001: Quantitative Methods in Linguistics",
    "section": "7 Communications",
    "text": "7 Communications\nI will respond to emails in a timely manner during normal working hours, but it may take longer if you email me after 5pm on weekdays, or any time during the weekend."
  },
  {
    "objectID": "syllabus.html#course-schedule",
    "href": "syllabus.html#course-schedule",
    "title": "Lin611-001: Quantitative Methods in Linguistics",
    "section": "8 Course Schedule",
    "text": "8 Course Schedule\nThe topics and readings listed here are the tentative schedule for the course. We may find, in the room, that some topics will take longer than initially scheduled.\n\n\n\n\n\n\n\n\n\n\n\nWeek\nDates\nTopics\nReadings\nNotes\n\n\n\n\n1\nJan 10,12\nOnboarding\nGithub Onboarding with RStudio\nSupplementary Resources\nR4DS: RMarkdown\nQuarto Tutorial: Hello Quarto\nQuarto Tutorial: Computations\nQuarto Tutorial: Authoring\n\n\n2\nJan 17, 19\nIntroduction to R\nWinter, Ch 1\nSupplementary Resources:\nHands-On Programming with R, Chapter 2\n2017 LSA Course: Introduction to R\n\n\n3\nJan 24, 26\nTidyverse and Workflows\nWinter, Ch 2\nSupplementary Resources:\nR4DS, Tidy Data\nR4DS, Data-visualization\n2017 LSA Course: Data Frames\n2017 LSA Course: Split-Apply-Combine\n2017 LSA Course: ggplot2\ntidyr cheat sheet (pdf)\ndplyr cheat sheet (pdf)\nggplot2 cheat sheet (pdf)\n\n\n4\nJan 31, Feb 02\nTidyverse and Workflows (part 2)\nWinter, Ch 2\n‚Äô‚Äô\n\n\n5\nFeb 07, 09\nDescriptive Statistics, Models, and Distributions\nWinter, Ch3\nSupplementary Resources:\nR4DS, Exploratory Data Analysis\n\n\n6\nFeb 14, 16\nIntro to Linear Models\nWinter Ch4\nSupplementary Resources\nR4DS: Model Basics\n2017 LSA Course: Fitting Linear Models\n\n\n7\nFeb 21, 23\nCorrelations and Transformations\nWinter Ch5\nSupplementary Resources\nR4DS: Model Basics\n2017 LSA Course: Fitting Linear Models\n\n\n8\nFeb 28, Mar 02\nMultiple Regression\nWinter Ch6\nSupplementary Resources\nR4DS: Model Basics\n2017 LSA Course: Fitting Linear Models\n\n\n9\nMar 07, 09\nCategorical Predictors\nWinter Ch7\nMidterm Project Due\nSupplementary Resources\nforcats cheat sheet (pdf)\n\n\nSpring Break\nMar 14, 16\nNo class\nNo Class\n\n\n\n10\nMar 21, 23\nInteractions and Non-Linear Effects\nWinter Ch 8\nSupplementary Material\nS√≥skuthy (2017)\n\n\n11\nMar 28, 30\nInferential Statistics\nWinter Ch 9,10\nSupplementary Material\nWinter Ch 11\nVisualizing Cohen‚Äôs d\nKirby & Sonderegger (2018)\n\n\n12\nApr 04, 06\nGeneralized Linear Models\nWinter Ch 12\nSupplementary Material\nWinter Ch 13\n\n\n13\nApr 11, 13\nMixed Models\nWinter Ch 14\nSupplementary Material\n2017 LSA Course: Mixed Effects Models\n\n\n14\nApr 18, 20\nMixed Models\nWinter Ch 15\nSupplementary Material\n2017 LSA Course: Model Comparison and Bootstrapping\n\n\n15\nApr 25\nReview & Outlook\n\nWinter Ch 16\n\n\nFinals\nMay 04\n\n\nFinal Project Due / The Final-est Deadline"
  },
  {
    "objectID": "syllabus.html#course-evaluation",
    "href": "syllabus.html#course-evaluation",
    "title": "Lin611-001: Quantitative Methods in Linguistics",
    "section": "9 Course Evaluation",
    "text": "9 Course Evaluation\n\n\n\nGrade Components\n\n\n\nWork-through Blog\n30%\n\n\nExercises\n20%\n\n\nMidterm Project\n20%\n\n\nFinal Project\n20%\n\n\nEngagement\n10%\n\n\n\n\n\nGrading Scale\n\n\n\nA\n>= 90\n\n\nB\n80 to 89\n\n\nC\n70 to 79\n\n\nD\n60 to 69\n\n\nE\n<= 59\n\n\n\n\n\n\n\nAssignment Submission\nAssignments will be set on canvas, and you will submit notification of the assignment‚Äôs completion through canvas. The content of the assignment itself may be contained elsewhere (e.g.¬†the A&S RStudio server, or a Github repository).\n\n\nWork-through Blog\nAs we work through Winter (2019) chapter by chapter, you will need to update a Quarto blog in which you, at the very least, run every code chunk from the chapter. A template Quarto blog repository is already available on Github. These blog posts will be due at the end of the week in which we finish covering each chapter.\n\n\nExercises\nIn addition to running the code included in each chapter, there will also be occasional R programming exercises.\n\n\nMidterm Project\nThere will be a midterm project to analyze a sample data set utilizing the methods covered in the course up to that point, and to report on your analysis.\n\n\nFinal Project\nThere will also be a final project in the same format as the midterm project, but to extend your analysis tools to the fuller suite of methods covered in the course.\n\n\nEngagement\nInspired by Kirby Conrod‚Äôs approach to Participation Grades\n\nThis portion of the grade is a way for me to give you credit for informal/unstructured collaborative work that you do. Participation and collaboration are strong predictors of success and learning retention, so please make an effort to find a way that works well for you to participate and engage with your colleagues.\n\nA well known process for solving programming problems is ‚ÄúRubber Duck Debugging.‚Äù It works by describing how each step of a program is supposed to work to another person or, as the name suggests, a rubber duck. Often the solution to the problem or the typo causing the bug jumps out at you during the process. Having a study buddy or study group could be really helpful if only for this purpose."
  },
  {
    "objectID": "syllabus.html#late-submissions-and-re-submissions",
    "href": "syllabus.html#late-submissions-and-re-submissions",
    "title": "Lin611-001: Quantitative Methods in Linguistics",
    "section": "10 Late Submissions and Re-submissions",
    "text": "10 Late Submissions and Re-submissions\nEvery graded piece of work will have a due date. After a 2 day grace period, there will be a single, flat 5% deduction from late work, whenever it is submitted between the due date and the The Final-est Deadline\n\nMidterm Grades\n\nAdd to Calendar\n\n\nI will submit midterm grades on March 13, 2023, at the end of the midterm grading window. Any unsubmitted assignments that were due before March 13 will be given a grade of 0, BUT you can still submit those assignments after March 13 for their inclusion in the final grade.\n\n\nThe Final-est Deadline\n\nAdd to Calendar\n\n\nThe final-est deadline by which to submit any material to be graded is May 4, 2023. I have to set this hard deadline in order to have enough time to conclude final grading in time for the university‚Äôs final grade submission deadline."
  },
  {
    "objectID": "syllabus.html#group-work-and-code-sources",
    "href": "syllabus.html#group-work-and-code-sources",
    "title": "Lin611-001: Quantitative Methods in Linguistics",
    "section": "11 Group Work and Code Sources",
    "text": "11 Group Work and Code Sources\nIt is acceptable to collaborate and confer with other students in the course. Any collaboration should be indicated in the assignment submission. You may also refer to code sources from elsewhere on the internet, as long as you also document the source, and explain what the code does. You might not receive credit for code which has been copied wholesale from another online source or from another student without credit or documentation.\n\nLarge Language Model (a.k.a. AI) Generated Code\nThere are a number of services that will generate code based on natural language queries. Some words of warning:\n\nFluent BS\nLarge Language Models have been found to generate code that looks superficially correct, but often does not actually run properly, or do what the human asker wanted. Being able to successfully identify where or why code does not work correctly is not always straight forward. This issue led the Q&A site StackOverflow to ban submissions generated by LLMs, stating\n\n[‚Ä¶] because GPT is good enough to convince users of the site that the answer holds merit, signals the community typically use to determine the legitimacy of their peers‚Äô contributions frequently fail to detect severe issues with GPT-generated answers.\n\n\n\nExplain what the code does\nAs stated above, you should provide credit to any external sources you turned to for code help, and explain what the resulting code does."
  },
  {
    "objectID": "syllabus.html#attendance-and-engagement",
    "href": "syllabus.html#attendance-and-engagement",
    "title": "Lin611-001: Quantitative Methods in Linguistics",
    "section": "12 Attendance and Engagement",
    "text": "12 Attendance and Engagement\nYou are expected to attend all scheduled course meetings. It would be helpful, but not necessary, if you let me know in advance if you are going to miss any lectures.\nIf you feel sick in any way, including but not limited to the well-known symptoms of COVID-19 (loss of taste or smell, a new and persistent cough, high fever, etc), do not come to class. There are other mechanisms for demonstrating engagement than attending lectures.\nI will also expect all of us in the course to treat each other with respect and civility in all aspects of the course, including\n\nIn the audio of a Zoom meeting\nIn the text chat of a Zoom meeting\nOn any course discussion boards or other forums."
  },
  {
    "objectID": "syllabus.html#academic-conduct",
    "href": "syllabus.html#academic-conduct",
    "title": "Lin611-001: Quantitative Methods in Linguistics",
    "section": "13 Academic Conduct",
    "text": "13 Academic Conduct\nUK Senate rules on academic offences: https://www.uky.edu/universitysenate/ao\nAppropriating someone else‚Äôs work and portraying it as your own is cheating. Collaborating with someone and portraying that work as solely your own is cheating. Obtaining answers to homework assignments or exams from previous semesters is cheating. Using an internet search engine to look up a question and reporting that answer as your own is cheating. Falsifying data or experimental results is cheating. If you are unsure about whether a specific action is cheating, you may check with me.\nThe minimum penalty for a first offense is a zero on the assignment on which the offense occurred. If the offense is considered severe or if the student has other academic offenses on their record, more serious penalties, up to suspension from the University may be imposed.\nWhen students submit work purporting to be their own, but which in any way borrows ideas, organization, wording or anything else from another source without appropriate acknowledgement of the fact, the students are guilty of plagiarism. Plagiarism includes reproducing someone else‚Äôs work, whether it be a published article, chapter of a book, a paper from a friend or some file, or something similar to this. Plagiarism also includes the practice of employing or allowing another person to alter or revise the work which a student submits as their own, whoever that other person may be.\nStudents may discuss assignments among themselves or with an instructor or tutor, but when the actual work is done, it must be done by the student, and the student alone. When a student‚Äôs assignment involves research in outside sources of information, the student must carefully acknowledge exactly what, where and how they employed them. If the words of someone else are used, the student must put quotation marks around the passage in question and add an appropriate indication of its origin. Making simple changes while leaving the organization, content and phraseology intact is plagiaristic. However, nothing in these Rules shall apply to those ideas which are so generally and freely circulated as to be a part of the public domain (University Senate Rules Section 6.3.1)."
  },
  {
    "objectID": "syllabus.html#university-academic-policy-statements",
    "href": "syllabus.html#university-academic-policy-statements",
    "title": "Lin611-001: Quantitative Methods in Linguistics",
    "section": "14 University Academic Policy Statements",
    "text": "14 University Academic Policy Statements\nLink to University Senate Academic Policy Statements https://www.uky.edu/universitysenate/acadpolicy\n\nExcused Absences and Acceptable Excuses\n\nExcused Absences: Senate Rules 5.2.5.2.1 defines the following as acceptable reasons for excused absences: (a) significant illness, (b) death of a family member, (c) trips for members of student organizations sponsored by an educational unit, trips for University classes, and trips for participation in intercollegiate athletic events, (d) major religious holidays, (e) interviews for graduate/professional school or full-time employment post-graduation, and (f) other circumstances found to fit ‚Äúreasonable cause for nonattendance‚Äù by the instructor of record. Students should notify the professor of absences prior to class when possible.\nIf a course syllabus requires specific interactions (e.g., with the instructor or other students), in situations where a student‚Äôs total EXCUSED absences exceed 1/5 (or 20%) of the required interactions for the course, the student shall have the right to request and receive a ‚ÄúW,‚Äù or the Instructor of Record may award an ‚ÄúI‚Äù for the course if the student declines a ‚ÄúW.‚Äù (Senate Rules 5.2.5.2.3.1)\n\n\n\nReligious Observances\n\nReligious Observances: Students anticipating an absence for a major religious holiday are responsible for notifying the instructor in writing of anticipated absences due to their observance of such holidays. Senate Rules 5.2.5.2.1(4) requires faculty to include any notification requirements within the syllabus. If no requirement is specified, two weeks prior to the absence is reasonable and should not be given any later. Information regarding major religious holidays may be obtained through the Ombud‚Äôs websiteor calling 859-257-3737.\n\n\n\nVerification of Absences\n\nVerification of Absences:Students may be asked to verify their absences in order for them to be considered excused. Senate Rule 5.2.5.2.1 states that faculty have the right to request appropriate verification when students claim an excused absence due to: significant illness; death in the household, trips for classes, trips sponsored by an educational unit and trips for participation related to intercollegiate athletic events; and interviews for full-time job opportunities after graduation and interviews for graduate and professional school. (Appropriate notification of absences due to University-related trips is required prior to the absence when feasible and in no case more than one week after the absence.)\n\n\n\nMake-Up Work\n\nMake-Up Work: Students missing any graded work due to an excused absence are responsible: for informing the Instructor of Record about their excused absence within one week following the period of the excused absence (except where prior notification is required); and for making up the missed work. The instructor must give the student an opportunity to make up the work and/or the exams missed due to the excused absence, and shall do so, if feasible, during the semester in which the absence occurred. The instructor shall provide the student with an opportunity to make up the graded work and may not simply calculate the student‚Äôs grade on the basis of the other course requirements, unless the student agrees in writing. According to SR 5.2.5.2.2, if a student adds a class after the first day of classes and misses graded work, the instructor must provide the student with an opportunity to make up any graded work.\n\n\n\nExcused Absences for Military Duties\n\nExcused Absences for Military Duties: If a student is required to be absent for one-fifth or less of the required course interactions (e.g., class meetings) due to military duties, the following procedure (per SR 5.2.5.2.3.2) shall apply:\n\nOnce a student is aware of a call to duty, the student shall provide a copy of the military orders to the Director of the Veterans Resource Center. The student shall also provide the Director with a list of his/her courses and instructors.\nThe Director will verify the orders with the appropriate military authority, and on behalf of the military student, notify each Instructor of Record via Department Letterhead as to the known extent of the absence.\nThe Instructor of Record shall not penalize the student‚Äôs absence in any way and shall provide accommodations and timeframes so that the student can make up missed assignments, quizzes, and tests in a mutually agreed upon manner.\n\n\n\n\nUnexcused Absences\n\nUnexcused Absences: If an attendance/interaction policy is not stated in the course syllabus or the policy does not include a penalty to the student, the instructor cannot penalize a student for any unexcused absences. (SR 5.2.5.2.3.3)\n\n\n\nPrep Week and Reading Days\n\nPrep Week and Reading Days: Per Senate Rules 5.2.5.6, the last week of instruction of a regular semester is termed ‚ÄúPrep Week.‚Äù This phrase also refers to the last three days of instruction of the summer session and winter intersession. The Prep Week rule applies to ALL courses taught in the fall semester, spring semester, and summer session, including those taught by distance learning or in a format that has been compressed into less than one semester or session. This rule does not apply to courses in professional programs in colleges that have University Senate approval to have their own calendar.\nMake-up exams and quizzes are allowed during Prep Week. In cases of ‚ÄúTake Home‚Äù final examinations, students shall not be required to return the completed examination before the regularly scheduled examination period for that course. No written examinations, including final examinations, may be scheduled during the Prep Week. No quizzes may be given during Prep Week. No project/lab practicals/paper/presentation deadlines or oral/listening examinations may fall during the Prep Week unless it was scheduled in the syllabus AND the course has no final examination (or assignment that acts as a final examination) scheduled during finals week. (A course with a lab component may schedule the lab practical of the course during Prep Week if the lab portion does not also require a Final Examination during finals week.) Class participation and attendance grades are permitted during Prep Week. The Senate Rules permit continuing into Prep Week regularly assigned graded homework that was announced in the class syllabus.\nFor fall and spring semester, the Thursday and Friday of Prep Week are study days (i.e.¬†‚ÄúReading Days‚Äù). There cannot be any required ‚Äúinteractions‚Äù on a Reading Day. ‚ÄúInteractions‚Äù include participation in an in-class or online discussion, attendance at a guest lecture, or uploading an assignment. See Senate Rules 9.1 for a more complete description of required interactions.\n\n\n\nAccommodations Due to Disability\n\nAccommodations Due to Disability: In accordance with federal law, if you have a documented disability that requires academic accommodations, please inform your instructor as soon as possible during scheduled office hours. In order to receive accommodations in a course, you must provide your instructor with a Letter of Accommodation from the Disability Resource Center (DRC). The DRC coordinates campus disability services available to students with disabilities. It is located on the corner of Rose Street and Huguelet Drive in the Multidisciplinary Science Building, Suite 407. You can reach them via phone at (859) 257-2754, via email (drc@uky.edu) or visit their website (uky.edu/DisabilityResourceCenter). DRC accommodations are not retroactive and should therefore be established with the DRC as early in the semester as is feasible.\n\n\n\nNon-Discrimination Statement and Title IX Information\n\nNon-discrimination and Title IX policy: In accordance with federal law, UK is committed to providing a safe learning, living, and working environment for all members of the University community. The University maintains a comprehensive program which protects all members from discrimination, harassment, and sexual misconduct. For complete information about UK‚Äôs prohibition on discrimination and harassment on aspects such as race, color, ethnic origin, national origin, creed, religion, political belief, sex, and sexual orientation, please see the electronic version of UK‚Äôs Administrative Regulation 6:1 (‚ÄúPolicy on Discrimination and Harassment‚Äù) (https://www.uky.edu/regs/ar6-1). In accordance with Title IX of the Education Amendments of 1972, the University prohibits discrimination and harassment on the basis of sex in academics, employment, and all of its programs and activities. Sexual misconduct is a form of sexual harassment in which one act is severe enough to create a hostile environment based on sex and is prohibited between members of the University community and shall not be tolerated. For more details, please see the electronic version of Administrative Regulations 6:2 (‚ÄúPolicy and Procedures for Addressing and Resolving Allegations of Sexual Harassment Under Title IX and Other Forms of Sexual Misconduct‚Äù) (https://www.uky.edu/regs/sites/www.uky.edu.regs/files/files/ar/ar_6.2-in...). Complaints regarding violations of University policies on discrimination, harassment, and sexual misconduct are handled by the Office of Institutional Equity and Equal Opportunity (Institutional Equity), which is located in 13 Main Building and can be reached by phone at (859) 257-8927. You can also visit Institutional Equity‚Äôs website (https://www.uky.edu/eeo).\nFaculty members are obligated to forward any report made by a student related to discrimination, harassment, and sexual misconduct to the Office of Institutional Equity. Students can confidentially report alleged incidences through the Violence Intervention and Prevention Center (https://www.uky.edu/vipcenter), Counseling Center (https://www.uky.edu/counselingcenter), or University Health Service (https://ukhealthcare.uky.edu/university-health-service/student-health).\nReports of discrimination, harassment, or sexual misconduct may be made via the Institutional Equity‚Äôs website (https://www.uky.edu/eeo); at that site, click on ‚ÄúMake a Report‚Äù on the left-hand side of the page.\n\n\n\nRegular and Substantive Interaction\n\nRegular and Substantive Interaction: All credit-bearing courses must support regular and substantive interaction (RSI) between the students and the instructor, regardless of the course‚Äôs delivery mode (e.g., in-person, hybrid, or online). Courses satisfy this requirement when course participants meet regularly as prescribed in SR 10.6, and the Instructor of Record substantively interacts with students in at least two of the following ways: provides direct instruction; assesses students‚Äô learning; provides information or responds to students‚Äô questions; and facilitates student discussions. Some exceptions allowed as per SACSCOC. For further information about the RSI requirement, see the Compliance Resources link on the Teaching, Learning and Academic Innovation Compliance page."
  },
  {
    "objectID": "syllabus.html#diversity-equity-and-inclusion",
    "href": "syllabus.html#diversity-equity-and-inclusion",
    "title": "Lin611-001: Quantitative Methods in Linguistics",
    "section": "15 Diversity, Equity and Inclusion",
    "text": "15 Diversity, Equity and Inclusion\nThe University of Kentucky is committed to our core values of diversity and inclusion, mutual respect and human dignity, and a sense of community (Governing Regulations XIV). We acknowledge and respect the seen and unseen diverse identities and experiences of all members of the university community (https://www.uky.edu/regs/gr14). These identities include but are not limited to those based on race, ethnicity, gender identity and expressions, ideas and perspectives, religious and cultural beliefs, sexual orientation, national origin, age, ability, and socioeconomic status. We are committed to equity and justice and providing a learning and engaging community in which every member is engaged, heard, and valued.\nWe strive to rectify and change behavior that is inconsistent with our principles and commitment to diversity, equity, and inclusion. If students encounter such behavior in a course, they are encouraged to speak with the instructor of record and/or the Office of Institutional Equity and Equal Opportunity. Students may also contact a faculty member within the department, program director, the director of undergraduate or graduate studies, the department chair, any college administrator, or the dean. All of these individuals are mandatory reporters under University policies.\nhttps://www.uky.edu/universitysenate/syllabus-dei"
  },
  {
    "objectID": "class_notes.html",
    "href": "class_notes.html",
    "title": "Class Notes",
    "section": "",
    "text": "Tidy Vowel Normalization\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 2, 2023\n\n\nJosef Fruehwald\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTidying and Plotting\n\n\n\n\n\n\n\n\n\n\n\n\nJan 31, 2023\n\n\nJosef Fruehwald\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nContinuing with the tidyverse\n\n\n\n\n\n\n\n\n\n\n\n\nJan 26, 2023\n\n\nJosef Fruehwald\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStarting with the tidyverse\n\n\n\n\n\n\n\n\n\n\n\n\nJan 24, 2023\n\n\nJosef Fruehwald\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDownloading OSF Data\n\n\n\n\n\n\n\nosf\n\n\ndata download\n\n\n\n\n\n\n\n\n\n\n\nJan 17, 2023\n\n\nJosef Fruehwald\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBasics of R Syntax\n\n\n\n\n\n\n\nR basics\n\n\n\n\n\n\n\n\n\n\n\nJan 17, 2023\n\n\nJosef Fruehwald\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlan for Onboarding Day\n\n\n\n\n\n\n\nBlock 1\n\n\nOnboarding\n\n\n\n\n\n\n\n\n\n\n\nJan 12, 2023\n\n\nJosef Fruehwald\n\n\n\n\n\n\n  \n\n\n\n\nGithub Onboarding with RStudio\n\n\n\n\n\n\n\nOnboarding\n\n\n\n\n\n\n\n\n\n\n\nJan 12, 2023\n\n\nJosef Fruehwald\n\n\n\n\n\n\n  \n\n\n\n\nWelcome Day\n\n\n\n\n\n\n\n\n\n\n\n\nJan 10, 2023\n\n\nJosef Fruehwald\n\n\n\n\n\n\nNo matching items\n\nReuseCC-BY-SA 4.0"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "The topics and readings listed here are the tentative schedule for the course. We may find, in the room, that some topics will take longer than initially scheduled.\n\n\n\nWeek\nDates\nTopics\nReadings\nSupplementary Resources\nNotes\n\n\n\n\n1\nJan 10,12\nOnboarding\nGithub Onboarding with RStudio\nR4DS: RMarkdown\nQuarto Tutorial: Hello Quarto\nQuarto Tutorial: Computations\nQuarto Tutorial: Authoring\n\n\n\n2\nJan 17, 19\nIntroduction to R\nWinter, Ch 1\nHands-On Programming with R, Chapter 2\n2017 LSA Course: Introduction to R\nChapter 1 blog due Friday\n\n\n3\nJan 24, 26\nTidyverse and Workflows\nWinter, Ch 2\nR4DS, Tidy Data\nR4DS, Data-visualization\n2017 LSA Course: Data Frames\n2017 LSA Course: Split-Apply-Combine\n2017 LSA Course: ggplot2\ntidyr cheat sheet (pdf)\ndplyr cheat sheet (pdf)\nggplot2 cheat sheet (pdf)\n\n\n\n4\nJan 31, Feb 02\nTidyverse and Workflows (part 2)\nWinter, Ch 2\n\nChapter 2 blog due Friday\n\n\n5\nFeb 07, 09\nDescriptive Statistics, Models, and Distributions\nWinter, Ch3\nR4DS, Exploratory Data Analysis\nChapter 3 blog due Friday\n\n\n6\nFeb 14, 16\nIntro to Linear Models\nWinter Ch4\nR4DS: Model Basics\n2017 LSA Course: Fitting Linear Models\nChapter 4 blog due Friday\n\n\n7\nFeb 21, 23\nCorrelations and Transformations\nWinter Ch5\nR4DS: Model Basics\n2017 LSA Course: Fitting Linear Models\nChapter 5 blog due Friday\n\n\n8\nFeb 28, Mar 02\nMultiple Regression\nWinter Ch6\nR4DS: Model Basics\n2017 LSA Course: Fitting Linear Models\nChapter 6 blog due Friday\n\n\n9\nMar 07, 09\nCategorical Predictors\nWinter Ch7\nforcats cheat sheet (pdf)\nChapter 7 blog due Friday\nMidterm Project Due\n\n\nSpring Break\nMar 14, 16\nNo class\nNo Class\n\n\n\n\n10\nMar 21, 23\nInteractions and Non-Linear Effects\nWinter Ch 8\nS√≥skuthy (2017)\nChapter 8 blog due Friday\n\n\n11\nMar 28, 30\nInferential Statistics\nWinter Ch 9,10\nWinter Ch 11\nVisualizing Cohen‚Äôs d\nKirby & Sonderegger (2018)\nChapter 9, 10 blog due Friday\n\n\n12\nApr 04, 06\nGeneralized Linear Models\nWinter Ch 12\nWinter Ch 13\nChapter 12 blog due Friday\n\n\n13\nApr 11, 13\nMixed Models\nWinter Ch 14\n2017 LSA Course: Mixed Effects Models\nChapter 14 blog due Friday\n\n\n14\nApr 18, 20\nMixed Models\nWinter Ch 15\n2017 LSA Course: Model Comparison and Bootstrapping\nChapter 15 blog due Friday\n\n\n15\nApr 25\nReview & Outlook\n\nWinter Ch 16\n\n\n\nFinals\nMay 04\n\n\n\nFinal Project Due\n\n\n\n\n\n\nReuseCC-BY-SA 4.0"
  }
]